%% uctest.tex
%% See accompanying LICENSE file for licensing, history, and copyright
%% information.

% This line is required for LPPL compliance.
\message{You are using a modified uctest.tex}
% Note that if you turn this file into a Derived Work that is not intended as a
% replacement for the original template (i.e. an actual thesis), and you do not
% imply that anyone provides support for your modified version, you may
% distribute it under any license you wish.

\documentclass[11pt]{ucscthesis}
\def\dsp{\def\baselinestretch{2.0}\large\normalsize}
\dsp

% 2010june01 sol katzman:
% package geometry should override the various margin settings from .clo and .cls
% and also eliminates issues where the default papersize is A4
\usepackage[letterpaper, left=1.5in, right=1.25in, top=1.25in, bottom=1.25in, includefoot]{geometry}
% Use PostScript fonts as required by UCSC Dissertation Preparation Guidelines
\usepackage{pslatex}
\usepackage{graphicx}
\usepackage{tabularx}
\usepackage{float}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{multirow}



\usepackage{etoolbox}
\AtBeginEnvironment{tabular}{\def\baselinestretch{1.0}\large\normalsize}% Single spacing in tabular environment
\AtBeginEnvironment{algorithm}{\def\baselinestretch{1.0}\large\normalsize}% Single spacing in algorithm environment

\ifdefined\HCode
    \usepackage[tex4ht]{hyperref}
\else
    \usepackage[colorlinks=true, allcolors=blue]{hyperref}
\fi

%Notation for graphs
\newcommand{\nodelabel}[1]{\ensuremath{\ell\left( #1 \right)}}
\newcommand{\leftside}[1]{\ensuremath{{ #1 }^{-}}}
\newcommand{\rightside}[1]{\ensuremath{{ #1 }^{+}}}
\newcommand{\forwardnode}[1]{\ensuremath{\protect\overrightarrow{ #1 }}}
\newcommand{\reversenode}[1]{\ensuremath{\protect\overleftarrow{ #1 }}}
\newcommand{\rtop}[1]{\mathrm{top}(#1)}
\newcommand{\rbottom}[1]{\mathrm{bottom}(#1)}
\newcommand{\rleft}[1]{\mathrm{left}(#1)}
\newcommand{\rright}[1]{\mathrm{right}(#1)}
\newcommand{\minstart}[1]{\mathrm{minstart}(#1)}
\newcommand{\minend}[1]{\mathrm{minend}(#1)}
\newcommand{\reversecomplement}[1]{\ensuremath{\textsc{revcomp}({ #1 })}}
\newcommand{\core}[1]{\mathrm{core}(#1)}
\newcommand{\aggstart}[1]{\mathrm{aggstart}(#1)}
\newcommand{\aggend}[1]{\mathrm{aggend}(#1)}
\newcommand{\agghash}[1]{\mathrm{hash}(#1)}
\newcommand{\toilvgcommit}[2]{\href{https://github.com/vgteam/toil-vg/commit/#1}{#2}}
\newcommand{\docker}[1]{\href{https://#1}{Quay}}
\newcommand{\faDownload}{X}
\newcommand{\indexurl}[1]{\href{#1}{\faDownload}}
\newcommand{\vgcommit}[2]{\href{https://github.com/vgteam/vg/commit/#1}{#2}}



\newcommand{\param}[1]{\emph{#1}}
\newcommand{\vocab}[1]{\emph{#1}}


\begin{document}

% Declarations for Front Matter

\title{Data structures and algorithms for read mapping to pangenome graphs}
\author{Xian H. Chang}
\degreeyear{2024}
\degreemonth{December}
\degree{DOCTOR OF PHILOSOPHY}
\chair{Professor Benedict Paten}
\committeememberone{Professor David Haussler}
\committeemembertwo{Professor Russell Corbett-Detig}
\committeememberthree{Professor Jian Ma}
\numberofmembers{4} %% (including chair) possible: 3, 4, 5, 6
\deanlineone{Dean Peter Biehl}
\deanlinetwo{Vice Provost and Dean of Graduate Studies}
\deanlinethree{}
\field{Biomolecular Engineering \& Bioinformatics}
\campus{Santa Cruz}

\begin{frontmatter}

\maketitle
\copyrightpage

\tableofcontents
\listoffigures
\listoftables
\listofalgorithms

\begin{abstract}
The human reference genome is one of the most important foundational resources in biological research, but its utility as a reference for all people is limited due to its lack of diversity.
Pangenomes are an alternative representation of genomes that incorporate genetic variations from a population of individuals.
Using a pangenome as a reference can mitigate the bias incurred by using the current standard reference genome, but because of the increased size and complexity of pangenomes, tools that use them tend to be slower and less reliable than tools that use standard references.
Mapping sequencing reads to a reference, the first step in many genomic pipelines, is a particularly challenging problem in a pangenome context. 
In this dissertation I present my work developing data structures and algorithms to support read mapping to pangenome graphs.
The pangenomic read mapping tools that I helped develop over the course of my PhD are as efficient as linear mappers and improve variant calling results when used with standard tools.
They are among the first practical pangenome mappers that are paving the way for the emerging field of pangenomics.% more accurate and unbiased genomic analyses.


\end{abstract}

\begin{dedication}
\null\vfil
{\large
\begin{center}
To myself,\\\vspace{12pt}
Perry H. Disdainful,\\\vspace{12pt}
the only person worthy of my company.
\end{center}}
\vfil\null
\end{dedication}


\begin{acknowledgements}
I want to ``thank'' my committee, without whose ridiculous demands, I
would have graduated so, so, very much faster.
\end{acknowledgements}

\end{frontmatter}


\chapter{Introduction}

The human reference genome is one of the most widely used resources in biological research.
It is the basis for studying the functional biology of the human genome, genetic variations and their implications in disease, evolutionary relationships between humans and other species, and countless other basic biological and clinical questions.
As a ``reference'', the reference genome serves as a standard scaffold against which new genomic data is compared.
In order for a reference to be effective, it must be similar enough to the sample that they can be meaningfully compared and differences between them identified and interpreted.
However, the human reference genome is a linear genome that represents a single haplotype copy of a genome with a limited number of alternate alleles.
Because of its lack of diversity, the reference genome can differ significantly from an individual's genome and can bias new samples to appear more similar to the reference than they actually are.
The human reference genome in its current iteration cannot represent the genetic diversity of the human population and is therefore limited in its utility as a reference for all humans.

One emerging alternative to a linear reference genome is a pangenome reference that represents a collection of genomic sequences.
A pangenome can better represent the genetic makeup of a population and has been shown to improve genomic analyses by mitigating the reference bias inherent in using a linear genome.
%Although pangenomes have shown promising results, there is a dearth of methods for working with them, in stark contrast to the myriad of linear genome methods.
%Pangenomes are often represented using sequence graphs.
%In a sequence graph, nodes represent nucleotide sequences and edges occur between sequences that are adjacent in the haplotypes of the pangenome.
%While this is an efficient method for representing the large amount of repetitive sequence present in a pangenome, the structure of the graph can become topologically complex as more variants are added.
%As a result, existing pangenome tools tend to be slow, memory intensive, and can be confounded by complex and repetitive regions of the genome.
%In order for pangenomes to reach their full potential as a standard reference, new methods must be developed to make them practical for common genomic tasks.

Read mapping is one such fundamental task that is common to many modern genomic analyses.
%The goal of read mapping is to take a read, the nucleotide sequence of a DNA fragment that has been read by a sequencing machine, and find the location in the reference genome where the sequences most closely match.
%The alignment between sequencing reads and reference genomes can then be used in downstream analyses such as variant calling, which aims to detect variations between a sample and reference genome.
Read mapping is a well studied problem in a linear context, but it becomes more difficult when mapping to a larger and more complex pangenome reference.
In this dissertation, I present my work developing data structures and algorithms for mapping sequencing reads to pangenome graphs.
I first describe an index for finding the minimum distance between positions in a pangenome graph and an algorithm that uses it to cluster positions on the graph (Chapter~\ref{chapter:distance}.
Next, I describe a short read-to-pangenome mapper (Chapter~\ref{chapter:sr-giraffe}) and a long read-to-pangenome mapper (Chapter ~\ref{chapter:lr-giraffe}), and show how each improves variant calling and genotyping relative to standard linear pipelines.

\chapter{Background}
\label{chapter:background}

\section{Linear reference genomes}
\label{sec:background:linear-genomes}

A reference genome is a high-quality, annotated genome assembly that is taken as representative of a species. 
Nearly all aspects of modern genomics are in some way dependent on reference genomes.
They are the basis against which we describe and interpret variants and they underpin the bioinformatics tools used to perform analyses.
The completion of the Human Genome Project \cite{lander_initial_2001}, which produced the first human reference genome, was a landmark accomplishment and has been the foundation of much of modern genetic and genomic research.
However, the human reference genome fundamentally cannot represent the entirety of the human species.

The initial copy of the human reference genome was assembled from the genetic sequences of eight people, primarily from a single individual \cite{lander_initial_2001}.
This genome assembly is a ``linear'' genome that represents just one haplotype copy of a genome and no variations.
Moreover, it is a mosaic of a few individuals and represents alleles that are unique to those individuals, and combinations of alleles that did not exist in any individual.
The current reference genome, GRCh38 \cite{schneider_evaluation_2017}, has build upon the initial assembly by closing gaps, adding alternate loci, improving annotations, and generally improving the quality of the sequence.
However, there are still nearly 160 million base pairs of gaps in the GRCh38 assembly that remain unsequenced, as well as additional sequences that are erroneous, falsely duplicated, or artificially generated\cite{schneider_evaluation_2017,nurk_complete_2022}.
Furthermore, 93\% of the sequence in GRCh38 is derived from just eleven individuals and about 70\% is derived from a single individual.

Many of these problems are improved upon in the recent CHM13 assembly, which is the first complete sequence of a human genome \cite{nurk_complete_2022}.
Unlike the GRCh38 assembly, the CHM13 assembly is the sequence of a single individual (a haploid hydatidiform mole) and includes the 8\% of the genome that remained unsequenced in GRCh38\cite{nurk_complete_2022}.
Despite these recent improvements, both CHM13 and GRCh38 have the fundamental problem that they represent just one haplotype sequence.
Although the GRCh38 assembly contains some alternate loci, these are are limited to 176 genomic regions\cite{schneider_evaluation_2017} and it is still essentially a linear genome.

%Surveys of human genetic variation: hapmap, 1000genomes, hgsvc

\subsection{Reference bias}

Using a linear genome as a reference for analyzing new samples introduces a bias causing the new sample to appear more similar to the reference \cite{ballouz_is_2019,noauthor_computational_2016,eizenga_pangenome_2020}.
This bias frequently arises when mapping to the reference genome, the first step of many common genomics pipelines.
Mapping to a linear reference can fail when there are significant differences between the sample and the reference, particularly when using short read sequences.
For example, if the sample contains a large insertion relative to the reference, the reference may not contain the sequence and a read originating from the insertion will remain unmapped (Figure \ref{fig:mapping_example}).
If no mapped reads cover the insertion, it cannot be called as a variant and the sample will likely appear to have the reference allele.

\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{mapping_example.pdf}
    \caption{(A) Mapping a read to a linear reference can fail if the sample has a large insertion relative to the reference. (B) Mapping to a pangenome that contains the variant sequence is more likely to succeed.}
    \label{fig:mapping_example}
\end{figure}



This reference bias can be mitigated by using a reference genome containing sequences that more closely resemble the sample of interest.
There have been many proposals for how a reference can accomplish this.
Rather than using a linear reference that is a mosaic of several individuals, such as GRCh38, the reference could be an ancestral genome that contains the most recent common ancestral allele at each locus, or a consensus genome that contains the most common allele at each locus.
Another alternative is to use a national or ethnic genome to represent a specific population \cite{ballouz_is_2019,chinese_national_genome_2023,korean_national_genome_2016,vietnamese_national_genome_2015,danish_national_genome_2015,swedish_national_genome_2018,kowal_race_2019}.
But while a population-specific reference may better capture variations that are frequent in that population, the benefit of such a reference will be minimal.
Most human genetic variation occurs across populations, rather than within populations \cite{nih_understanding_2007}, meaning that even when using a population-specific reference, the majority of the genome will still be subject to the same reference bias as would stem from using any randomly selected reference genome. 
%Furthermore, most human genetic variations are rare so no single reference scaffold will be able to represent all people equally. 


\subsection{Surveys of human genetic variation}

While the Human Genome Project provided a deep understanding of a single human genome, other large-scale projects aimed to provide a broad understanding of the genetic landscape of the human population.
Projects such as the dbSNP database \cite{sherry_dbsnp_2001}, International HapMap Consortium \cite{international_hapmap_consortium_international_2003,international2005haplotype}, ENCyclopedia of DNA Elements (ENCODE) project \cite{encode_project_consortium_encode_2004}, 1000 Genomes Project \cite{1000_genomes_project_consortium_map_2010,1000gp_2015}, and Human Genome Structural Variation Consortium (HGSVC) \cite{chaisson_sv_2019} have granted us a greater insight into human genetic variation, its role in functional biology, disease, and evolution, as well as its distribution across the globe.
Historically, many of these projects focused on European populations...
As sequencing technologies \cite{} and genome assembly algorithms \cite{} have advanced, these projects have been producing increasingly high-quality genomes and variant catalogues. 
This greater view of human genetic diversity both highlights the shortcomings of the human reference genome and provides a roadmap for how to create a reference that better represents all of humanity \cite{ballouz_is_2019,miga_need_2021}.

\section{Pangenomics}
\label{sec:background:pangenomes}

%TODO This should discuss HPRC, population pangenomes, etc

A pangenome is an alternative to a standard linear genome.
Pangenomes are collections of genomic sequences from a population and the alignments among them.
Because they can represent multiple sequences at each locus, they can better represent variations in a population and have been shown to reduce reference bias relative to using a linear genome \cite{sherman_pan-genomics_2020,noauthor_computational_2016,hprc_draft_2023}.
With recent advances in genome sequencing and assembly algorithms, it is now feasible to produce reference-quality and even telomere-to-telomere genome sequences with ever-decreasing time and cost\cite{}.
This technical capability coupled with our current understanding of population genetics makes it feasible to select and sequence genomes to accurately and efficiently represent the genetic diversity of a population. 

The first human reference pangenomes are just beginning to be produced.
The Human Pangenome Reference Consortium (HPRC) has build on the work of the Human Genome Project, the 1000 Genomes Project, and other sequencing projects to begin to establish a global human reference pangenome \cite{hprc_2022}.
The HPRC aims to produce a pangenome comprised of at least 350 individuals' genomes selected to maximally represent the genetic variant present in the human population \cite{hprc_2022}.
The initial draft of the HPRC's human reference pangenome contained the existing GRCh38 and CHM13 reference genomes as well as high-quality (average quality value of $53.57$), phased, and annotated genomes of 47 individuals selected from existing 1000 Genomes Project cell lines and prioritized for their coverage of genetic variants and biogeographic origin \cite{hprc_draft_2023}.
The HPRC released three different alignments of these haplotype sequences, constructed using the Minigraph \cite{li_minigraph_2020}, Minigraph-Cactus (MC)\cite{minigraph_cactus_2024}, and PanGenome Graph Builder (PGGB) \cite{pggb_2024} pipelines (see section \ref{sec:graph-construction}). 


There have been several recent efforts to establish ancestry-specific pangenomes for underrepresented populations \cite{pacific_pangenome_2024,chinese_pangenome_2023,arab_pangenome_2024}.
These pangenomes have been curated to represent the genetic diversity of Pacific, Chinese, or Arab populations.
For example, the Chinese pangenome sampled individuals from the 36 of the 55 officially recognized ethnic minority groups and 8 linguistic groups, with the goal of eventually representing all recognized minority groups as well as unrecognized groups\cite{chinese_pangenome_2023}.
These population-specific efforts aim to improve understanding of genetic variants and diseases that are specific to or more frequent in each population.


\section{Variation graphs}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{example_graph.pdf}
    \caption{A sequence graph representing two input sequences. Variations between the two sequences (in bold) are represented as forks in the graph.}
    \label{fig:example_graph}
\end{figure}

A human pangenome can 
A popular method of representing pangenome is with sequence graphs (Figure \ref{fig:example_graph}).
Nodes in a sequence graph are labeled with nucleotide sequences and longer sequences can be encoded as paths through the graph.
Divergences in the graph represent variations in the sequences.
Variation graphs are sequence graphs that additionally encode a set of reference paths through the graph.
These paths typically correspond to reference and alternate scaffolds.

Formally, a sequence graph is a bidirected graph $G = (V, E)$ where $V$ is the set of nodes and $E$ is the set of edges.
A node $v$ in a bidirected graph has two node sides, $\{v^{-}, v^{+}\}$, which are arbitrarily designated as ``left'' and ``right'' respectively (Figure \ref{fig:example_graph}).
Each node $v$ in a sequence graph is labeled with a nucleotide sequence, $s(v)$.
Edges in sequence graphs connect node sides and traversals of nodes must enter and exit the node at opposite sides.
A left-to-right traversal of a node is designated as a ``forward'' traversal and the nucleotide sequence is read in the forward direction; a right-to-left traversal is designated as a ``backward'' traversal and the nucleotide sequence is read as its reverse complement.
The variation graph toolkit (vg) is a software suite for working with variation graphs.

\section{Snarl decomposition}
\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{snarl_tree.pdf}
    \caption{(A) A sequence graph (left) and its corresponding snarl tree (right). Chains are represented by rectangular nodes in the snarl tree; snarls are represented by elliptical nodes.
    (B) A view of the graph in (A) with snarl $\{a^+$,$k^-\}$ replaced by its netgraph. In this view, the chains $\{b^+$, $d^-\}$ and $\{e^+$, $j^-\}$ are represented by nodes.}
    \label{fig:snarl_tree}
\end{figure}
To help find organization in a sequence graph, it is often useful to describe common topological motifs.
A simple variation such as a SNP or indel will be represented by one or two nodes representing the variant sequences, flanked by two nodes representing conserved sequences.
In Figure \ref{fig:snarl_tree}A, nodes $h$ and $i$ represent the alleles of a SNP while nodes $g$ and $j$ represent conserved sequence.
The subgraph between node sides $g^+$ and $j^-$ is called a snarl.
A snarl is defined by a pair of node sides, $\{x^{-/+}, y^{-/+}\}$, that delimit a subgraph between them.
The nodes $x$ and $y$ are referred to as the boundary nodes of the snarl.
Two node sides define a snarl if they are (i) separable: splitting the boundary nodes into the their two node sides disconnects the snarl from the rest of the graph, and (ii) minimal: there is no node $z$ within the snarl that is separable with the boundary nodes.
I will use the term ``snarl'' to refer to the two boundary nodes and the subgraph between them.

Snarls frequently occur successively with a shared boundary node between them.
A sequence of consecutive snarls is called a ``chain''.
In Figure \ref{fig:snarl_tree}A, the snarls $\{e^+$, $g^-$\} and $\{g^+$, $j^-\}$ are in a chain $\{e^+$, $j^-\}$.

Snarls and chains may be nested within each other.
Conceptually, this can occur when multiple variants affect the same locus, for example an insertion that contains a SNP.
In a graph, a snarl contains another snarl if all of the nodes in the latter snarl are contained in the subgraph of the former.
A snarl contains a chain if it contains all of the chain's component snarls.
In Figure \ref{fig:snarl_tree}A, the chain $\{e^+$, $j^-\}$ is contained in the snarl $\{a^+$, $k^-\}$.

%A sequence graph can be entirely decomposed into nested snarls and chains.
The nesting relationship of snarls and chains of a graph is described by its ``snarl tree'' (Figure \ref{fig:snarl_tree} A).
Each snarl and chain in the graph is represented as a node in the snarl tree.
A chain is a child of a snarl if it is contained in the snarl and no other descendent of the snarl.
A snarl is a child of a chain if it is a component of the chain.
Every snarl is a child of a chain; a chain containing just one snarl is called a ``trivial chain''.
Because of this, the snarl tree is composed of alternating layers of snarls and chains, starting with a top-level chain as the root.

Nodes, snarls, and chains all have the property that they are connected to the rest of the graph by two node sides.
Based on this property, snarls and chains can be treated as nodes within their parents, obscuring the presence of a subgraph between the boundaries of the child.
A ``netgraph'' is a view of a snarl where its child chains are replaced by nodes.
In Figure \ref{fig:snarl_tree}B, the snarl $\{a^+$, $k^-\}$ has been replaced with its netgraph.
For convenience, I will refer to nodes, snarls, and chains collectively as ``structures'' when referring to them as nested structures in a snarl tree.

\subsection{Graph construction}
\label{sec:graph-construction}
-VCF construction
-MC
-PGGB
How they produce graphs with different characteristics
Main difference between MC and PGGB graphs is the representation of CNVs

\section{Sequencing technologies}
\label{sec:background:sequencing}

\section{Read mapping}
\label{sec:background:mapping}
Most mapping algorithms, both linear and graph-based, follow a common seed-and-extend framework comprised of three main steps.
In the first step, seeding, short ``seed'' alignments are found between the read and reference.
Next, the seeds may be grouped together based on their locations in the reference to identify regions of the genome that are likely targets of mapping.
This step is either done by clustering or chaining, and is omitted entirely by some mappers.
In clustering, partitions of seeds are found such that seeds that are close to each other on the reference are placed in the same partition.
Chaining finds ordered sets of co-linear seeds that occur in the same order in the read and reference. 
Once a likely location is found on the reference, the final alignment step is done.
In this step, the seed alignment is extended using a dynamic programming algorithm to find the final base-level alignment.

Often in the literature, the terms ``mapping'' and ``alignment'' are used interchangeably.
For the sake of clarity, I will use ``mapping'' to refer to the problem of finding the location of a read in a reference, and ``alignment'' to refer to the problem of finding the optimal base-level alignment.
Alignment is typically a component of a mapping algorithm, used to find the optimal alignment to a smaller region of the reference.

\subsection{Seeding}

\subsection{Clustering}

\subsection{Chaining}

%TODO: This was in the lr giraffe paper. If it ends up in the actual version then this needs to be rewritten
%This recursion can be made more efficient using an auxiliary data structure for finding the best score within a range of previous anchors and a gap cost that can be efficiently computed without considering the sequence content of the read and reference\cite{myers_chaining_1995}.
%The chaining problem is well studied in a linear context\cite{myers_chaining_1995,shibuya_linear_chaining_2003,abouelhoda_linear_chaining_2005,jain_linear_chaining_2022}, but fewer algorithms exist to do chaining against graph references.
%Chaining becomes a more difficult problem in a graph context because the order and distance between anchors is ambiguous in a graph and can be expensive to compute.

%Many existing graph chaining algorithms are based on an algorithm from Makinen et al. that uses a minimum path cover of the graph to determine reachability and distance\cite{makinen_dag_chaining_2019}.
%The cost of this algorithm is parameterized by the width of the graph, making it efficient for most current human pangenome graphs for which a minimum path cover can be achieved with a small number of paths\cite{makinen_dag_chaining_2019}.
%The chaining algorithm in GraphChainer builds on this algorithm and allows overlaps of one node between anchors\cite{ma_graphchainer_2023}.
%PanAligner's chaining algorithm expands this technique to cyclic graphs\cite{panaligner_2024}.

%Minigraph uses a chaining algorithm based on that of Minimap2.
%Minigraph uses two rounds of chaining: it first produces linear chains within individual nodes in the graph, then makes chains of the linear chains taking into account the topology of the graph.
%The second round of chaining finds graph distances by enumerating up to 16 shortest-path walks between between pairs of linear chains.
%Of those paths, it chooses the path with length closest to the gap in the read for computing the gap cost\cite{minigraph_2020}.

\subsection{Alignment}

\subsection{Linear mappers}

Existing liner mappers generally use either suffix tree-based text indexes or $k$-mer indexes for seeding \cite{li_survey_2010}.
%also Slider, which uses merge sorting
Text indexes can be queried to find variable-length exact matches between a read and a reference; one common example of a text index is an FM-index, a low-memory index based on the Burrows Wheeler transform (BWT) \cite{li_bwa_mem_2013,langmead_bowtie2_2012,li_soap2_2009}.
$k$-mer based algorithms use an index that stores the locations of $k$-mers (sequences of length $k$) in the reference, then look up $k$-mers from the read to find matches in the reference.
Rather than storing the locations of every $k$-mer in the reference, many algorithms use different schemes for selecting a subset $k$-mers to be stored in the index \cite{li_minimap2_2018,lee_mosaik_2014,jain_mashmap_2018, edgar_urmap_2020,edgar_syncmers_2020}.
For a scheme to be effective for seeding alignments, it must sparsely sample the reference to reduce the size of the index, evenly sample sequences so that the gap between two consecutive seeds is small, and consistently sample sequences so that if two sequences are similar, then the $k$-mers selected will be the same \cite{marcais_improving_2017}.

I will be using minimizers for seeding; minimizers are a method for selecting $k$-mers that is used in several mappers.
A minimizer scheme is defined by two parameters, $k$ and $w$, and a function $f$ that determines an ordering of the $k$-mers.
Within a window of $w$ consecutive $k$-mers, the minimizer is the $k$-mer with the lowest value according to $f$.
A minimizer index stores the locations of minimizers from all windows in a sequence.
If two sequences share a subsequence of length at least $w+k-1$, then they will share a minimizer.


After extracting short seed alignments between the read and reference, the seeds are prioritized to avoid performing an expensive dynamic programming step on unlikely seeds.
Some algorithms prioritize individual seeds based on properties of the seed, such as the number of occurrences in the reference  \cite{langmead_bowtie2_2012}, and evaluate them in order of priority.
Others groups seeds by chaining or clustering and evaluate groups of seeds together \cite{li_bwa_mem_2013,li_minimap2_2018,lee_mosaik_2014,jain_mashmap_2018}.
These techniques partition seeds into groups of seeds that are near each other on the reference, in order to identify regions of the reference that contain potential alignments.
Chaining algorithms additionally require that seeds in a chain be co-linear\cite{li_bwa_mem_2013,li_minimap2_2018}.

The final base-level alignment is found using dynamic programming, either by extending seed alignments or by aligning the entire reads to a region of the reference that is found by clustering.
Standard dynamic programming algorithms, such as Smith-Waterman for local alignment, have prohibitive runtimes, so many mappers use different optimizations to speed up alignment and to reduce the search space of the dynamic programming matrix.
Some mappers use Single-Instruction Multiple-Data (SIMD) microprocessors to accelerate dynamic programming by parallelizing computation of independent cells in the dynamic programming matrix \cite{farrar_striped_2007,rognes_six-fold_2000}.
Banded alignment algorithms restrict the dynamic programming matrix to a diagonal ``band'' of a specified width, preventing large insertions or deletions that would exceed the width \cite{chao_aligning_1992}.
BLAST's X-drop algorithm fills in the matrix row by row, and stops extending each row when the best possible score is a given value X less than the best score seen in the previous row \cite{altschul_blast_1990}.
This has a similar effect to banded alignment in that it forces the alignment to remain close to the diagonal, preventing large insertions or deletions that could align the start of one sequence to the end of another.

\subsection{Graph mappers}

Mapping reads to graph references is a much newer and far less well studied problem than mapping to linear references.
In general, mapping to graph references is more accurate, but also requires more computational resources and improving read-to-graph mapping is still an open area of research.
Existing graph mappers generally follow the same seed-and-extend structure as linear mappers\cite{eizenga_pangenome_2020}.
Most graph mappers use a $k$-mer index for seeding \cite{rautiainen_graphaligner_2020,rakocevic_fast_2019,vaddadi_vmap_2019,schneeberger_simultaneous_2009}; others use generalizations of the BWT for indexing graphs \cite{garrison_variation_2018,kim_hisat2_2019}.

Clustering or chaining seeds in a graph is more difficult than in a linear genome due to the added ambiguity of calculating distance in a graph.
Different tools use a variety of estimations of distance based on embedded linear paths \cite{garrison_variation_2018}, the snarl decomposition \cite{rautiainen_graphaligner_2020}, an embedded representation of the graph \cite{vaddadi_vmap_2019}, or by enumerating linear paths through the graph \cite{li_minigraph_2020}.

Alignment is also more challenging in a graph context, particularly for cyclic graphs.
Many mappers use linear dynamic programming algorithms that have been extended to a graph context.
One such example is partial order alignment (POA), an algorithm for aligning to directed acyclic graphs (DAGs) \cite{lee_multiple_2002}.
Most mappers are restricted to aligning to DAGs \cite{schneeberger_simultaneous_2009,kim_hisat2_2019,rakocevic_fast_2019}.
VG-MAP can align to graphs of arbitrary topology by ``unrolling'' a graph to convert it to a DAG then using POA \cite{garrison_variation_2018}.
GraphAligner maps to cyclic graphs using a graph extension of Myers' bit parallel alignment algorithm \cite{rautiainen_bit-parallel_2019}

\chapter{Distance Indexing}
\label{chapter:distance}

\section{Preface}
This chapter is the full text of my paper "Distance Indexing and Seed Clustering in Sequence Graphs" \cite{chang_distance_2020}, which I presented and ISMB in 2020 and was published in Bioinformatics.
I am the sole first author of this paper. 
Jordan M. Eizenga originally conceptualized the idea of a snarl decomposition-based distance index and provided guidance and support throughout the process of software development and writing.
Jordan M. Eizenga, Adam M. Novak, and Jouni Sirén provided to minor contributions to the software development and conceptualization. 

While the majority of my work is done for variation graphs, the distance index is generalizable to sequence graphs as well.
Some notation in this chapter may differ from the rest of the thesis but the underlying structures they describe are the same.

\newpage

\section{Introduction}
Conventional reference genomes represent genomes as a string or collection of strings.
Accordingly, these so-called ‘linear reference genomes’ can only store one allele at each locus.
The resulting lack of diversity introduces a systematic bias that makes samples look more like the reference genome \cite{zook_integrating_2014}.
This reference bias can be reduced by using pangenomic models, which incorporate the genomic content of populations of individuals \cite{noauthor_computational_2016}.
Sequence graphs are a popular representation of pangenomes that can express all of the variation in a pangenome \cite{paten_genome_2017}. 
Sequence graphs have a more complex structure and the potential to contain more data than linear genomes.
This tends to make functions on a sequence graph more computationally challenging than analogous functions on linear genomes.

One such function is computing distance.
In a linear genome, the exact distance between two loci can be found by simply subtracting the offset of one locus from the offset of the other.
In a graph, calculating distance is much more complicated; there may be multiple paths that connect the two positions and different paths may be relevant for different problems.

Distance is a basic function that is necessary for many functions on genome graphs; in particular, calculating distance is essential for efficient mapping algorithms.
In a seed-and-extend paradigm, short seed matches between the query sequence and reference are used to identify small regions for expensive alignment algorithms to align to \cite{schneeberger_simultaneous_2009,li_minimap_2016,rakocevic_fast_2019,garrison_variation_2018,vaddadi_read_2019,rautiainen_bit-parallel_2019}. 
Often these regions are identified by clusters of matches. 
Clustering requires repeated distance calculations between seeds and can be very slow in graphs as large as whole genome graphs. 
The prohibitive run time of clustering algorithms can make them impractical for mapping and some mapping algorithms omit this step entirely \cite{rautiainen_bit-parallel_2019}.

We have developed an algorithm to calculate the exact minimum distance between any two positions in a sequence graph and designed an index to support it. We also developed a clustering algorithm that clusters seeds based on the minimum distance between them. Our algorithms are implemented as part of vg, a variation graph toolkit \cite{garrison_variation_2018}.

\section{Background}

\subsection{Sequence Graph Structure}


A sequence graph is a bidirected graph in which each node is labeled by a sequence of nucleotides.
A node $X$ has two sides, $\{x, \bar{x}\}$. For convenience, we will consider $x$  to be the ``left'' side and $\bar x$ to be the ``right''.
This induces a directionality on $X$, so that we may consider a left-to-right (or $x$ to $\bar{x}$) traversal of $X$ to be forward, and a right-to-left traversal backward.
However, we note that the designation of ``left'' and ``right'' is arbitrary.
They can be swapped without changing the underlying graph formalism.
Conceptually, a forward traversal corresponds to the forward strand, and a backward traversal corresponds to the reverse complement strand.

Paths in a bidirected graph must obey restrictions on both nodes and edges.
Edges connect two node sides rather than nodes.
A path consists of an alternating series of oriented nodes and edges.
The path must enter and exit each (non-terminal) node through opposite node sides.
In addition, there must exist an edge connecting consecutive nodes in the path, between the node side that is exited and the node side that is entered.

In Figure \ref{fig:aim1_examplegraph}, the graph has an edge between $\bar{a}$ and $b$.
A path including this edge would go from $A$ to $B$ traversing both forward, or from $B$ to $A$ traversing both backward.
    
Some applications use a specific articulation of a sequence graph called a variation graph.
A variation graph contains a set of embedded paths through the graph.
These paths typically correspond to the primary and alternate scaffolds of a reference genome.

\begin{figure}
\centering
\includegraphics[width=0.8\columnwidth]{aim1_examplegraph.png}
\caption[Snarl tree example]{Example sequence graph (top) and its snarl tree (bottom). Chains in the sequence graph are represented as rectangular nodes in the snarl tree and snarls are represented as elliptical nodes.}
\label{fig:aim1_examplegraph}
\end{figure}

\subsection{Snarl Decomposition}
In previous work, we proposed a decomposition for sequence graphs that describes their common topological features \cite{paten_superbubbles_2018}. 
A simple variant, such as an indel or SNP, will typically be represented as one or two nodes (corresponding to the different alleles), flanked by two more nodes (corresponding to adjacent conserved sequences. 
In Figure~\ref{fig:aim1_examplegraph}, nodes $A$, $J$, and $M$ all represent conserved sequences.
Nodes $K$ and $L$ represent two alternative sequences that occur between $J$ and $M$.
The subgraph between the two flanking nodes, in this case the subgraph containing nodes $J$,$K$, $L$, and $M$, is called a snarl.
Snarls can be seen as a generalization of the variant 'bubbles' used in many genome assembly algorithms \cite{paten_superbubbles_2018}.

A snarl is defined by a pair of node sides, $(x, y)$ that delimit a subgraph between them.
The nodes $X$ and $Y$ are called the boundary nodes of the snarl.
Two node sides define a snarl if they are (i) separable: splitting the boundary nodes into their two node sides disconnects the snarl from the rest of the graph, and (ii) minimal: there is no node $A$ in the snarl such that $(x, a)$ or $(\bar{a}, y)$ are separable.
In Figure~\ref{fig:aim1_examplegraph}, $\bar{g}$ and $i$ define a snarl $(\bar{g}, i)$.
We will sometimes abuse the terminology and use ``snarl'' to refer to both the pair of nodes and the subgraph that they separate from the rest of the graph.
Thus, we can say that the snarl $(\bar{g}, i)$ contains node $H$ and boundary nodes $G$ and $I$.


In sequence graphs, snarls often occur contiguously with a shared boundary node between them; a sequence of contiguous snarls is called a chain.
In Figure~\ref{fig:aim1_examplegraph}, the snarls $(\bar{b}, d)$ and $(\bar{d}, f)$ comprise a chain between $\bar{b}$ and $f$, which we refer to as $[\bar{b}, f]$.
A trivial chain is one that contains only one snarl; in Figure~\ref{fig:aim1_examplegraph}, snarl $(\bar{g}, i)$ is part of a trivial chain, chain $[\bar{g}, i]$.

Snarls and chains can be nested within other snarls. 
This nesting behavior often occurs when the same genomic element is affected by both point and structural variants, in which case the point variant's snarl nests inside the structural variant's snarl.
A snarl $(x, y)$ contains another snarl $(a, b)$ if all nodes in $(a, b)$ are contained in the subgraph of $(x, y)$.
In Figure~\ref{fig:aim1_examplegraph}, the snarl $(\bar{a}, j)$ contains snarls $(\bar{g}, i)$, $(\bar{b}, d)$, and $(\bar{d}, f)$.
A snarl contains a chain if each of the chain's snarls are in the subgraph of the containing snarl.

The nesting relationships of snarls and chains in a sequence graph is described by its snarl tree (Figure~\ref{fig:aim1_examplegraph}).
Each snarl or chain is represented in the snarl tree as a node. 
Since every snarl belongs to a (possibly trivial) chain, snarl trees have alternating levels of snarls and chains with a chain at the root of the tree.
We also refer to the root as the top-level chain.
A snarl is the child of a chain if it is a component of the chain.
A chain $[a, b]$ is a child of $(x, y)$ if $(x, y)$ contains $[a, b]$ and there are no snarls contained in $(x, y)$ that also contain $[a, b]$.


All nodes in a sequence graph will be contained by the decomposition of its snarls and chains, described by the snarl tree.
In general, the snarl tree can be arbitrarily deep and have very short chains.
However the snarl tree of a typical sequence graph will be shallow and have a long chain as the root.
The majority of snarls will be contained in this top-level chain. Small variants can nest within larger structural variants, contributing to the depth of the snarl tree.
However, in most parts of the genome, the rate of polymorphism is low enough that two variants are unlikely to overlap each other.
As a result, the depth of these nested variants is usually very small, typically less than $5$ in our observations.

Nodes, snarls, and chains are all two-ended structures that are connected to the rest of the graph by two node sides.
It is sometimes convenient to refer to a topological feature only by this shared property, and to be opaque about which topological feature it actually is.
In these cases, we will refer to the node, snarl, or chain generically as a ``structure''.
As with nodes of the sequence graph itself, structures are assigned an arbitrary orientation but we will assume that they are oriented left to right and refer to the left and right sides of structures as $struct$ and $\overline{struct}$ respectively.
Because of their shared two-ended property, structures can all be treated as single nodes in their parents.
The netgraph of a snarl is a view of the snarl where each of its child chains is replaced by a node.



\subsection{Prior Research}

\subsubsection{Distance in graphs}

Calculating distance in a graph is an extremely well studied topic.
Many graph distance algorithms improve upon classical algorithms, such as Dijkstra's algorithm \cite{dijkstra_note_1959} and A* \cite{hart_formal_1968}, by storing precomputed data in indexes.
These methods index the identities of important edges \cite{hutchison_partitioning_2005,lauther_extremely_2004} or distances between selected nodes \cite{dave_topcom:_2015,qiao_approximate_2012,goos_efficient_1997,akiba_fast_2013-1} then use the indexed information to speed up distance calculations.
Index-based algorithms must make a tradeoff between the size of the index and the speed of the distance query.

\subsubsection{Distance in sequence graphs}

Some sequence graph mapping algorithms use clustering steps based on different estimations of distance \cite{vaddadi_read_2019,garrison_variation_2018}. 
In \texttt{vg}, distance is approximated from the embedded paths.
This path-based method estimates the distance between two positions based on a nearby shared path.
The algorithm performs a bidirectional Dijkstra search from both positions until it finds at least one path in common from both positions.
This path is then used to estimate the distance between them. 


Some research has been done on finding solutions for more specific distance queries in sequence graphs.
PairG \cite{jain_validating_2019} is a method for determining the validity of independent mappings of reads in a pair by deciding whether there is a path between the mappings whose distance is within a given range.
This algorithm uses an index to determine if there is a valid path between two vertices in a single O(1) lookup.
Although this is an efficient solution for this particular problem, it cannot be used to query the exact distance between two nodes.
Rather, it returns a boolean value indicating whether two nodes are reachable within a range of distances, which is defined at index construction time.

\section {Minimum Distance}

Our minimum distance algorithm finds the minimum oriented traversal distance between two positions on a sequence graph. 
A position consists of a node, offset in the sequence, and orientation.
The oriented distance must originate from a path that starts traversing the first position in its given orientation and ends at the second position in its given orientation.


Our algorithm uses the snarl decomposition of sequence graphs to guide the calculation.
Because structures are connected to the rest of the graph by their boundary nodes, any path from a node inside a structure to any node not in that structure must pass through the structure's boundary nodes.
Similarly, any path between boundary nodes of snarls in a chain must pass through the boundary nodes of every snarl that occurs between them in the chain.
Because of this property, we can break up the minimum distance calculation into minimum distances from node and chain boundaries to the boundaries of their parent snarl, from snarl boundaries to their parent chain boundaries, and the distance between sibling structures in their parent structure (Figure \ref{fig:aim1_distance_calculation_example}).
We refer to this property of minimum distance calculation in structures as the split distance property.



\begin{figure}
    \centering
    \includegraphics[width=\columnwidth]{aim1_distance_calculation_example.png}
    \caption[Minimum distance calculation]{The minimum distance calculation from a position on $C$ to a position on $K$ can be broken up into the distances from each position to the ends of each of its ancestor structures in the snarl tree. Each colored arrow in the graph represents a distance query from a structure to a boundary node of its parent. The snarl tree node that each query occurs in is outlined with the same color. At the common ancestor of the positions, chain [$\bar{a}, m$], the distance is calculated between two of the chain's children, ($\bar{a}, j$) and ($\bar{j}, m$). }
    \label{fig:aim1_distance_calculation_example}
\end{figure}


\subsection{Minimum Distance Index}

We designed our minimum distance index to support distance queries between child structures in snarls and between boundary nodes of snarls in chains in constant time.
The overall minimum distance index consists of a snarl index for each snarl and a chain index for each chain in the graph.

\subsubsection{Snarl Index}

For each snarl, the index stores the minimum distances between every pair of node sides of child structures contained in the snarl, including the boundary nodes.
A distance query within a snarl is a simple constant time lookup of the distance.

\subsubsection{Chain Index}

For each chain, the index stores three arrays, each with one entry for each boundary node of the snarls in the chain.
The first, a prefix sum array, contains the minimum distance from the start of the chain to the left side of each of the boundary nodes of the snarls that comprise the chain.
This array can be used to find the distance between two of these snarls’ boundary nodes along the chain. Distances from a left-to-right traversal of the chain can be computed directly from the prefix sum array, whereas distances from a right-to-left traversal also require the length of the boundary nodes.
Since paths can reverse direction in the chain (Figure~\ref{fig:aim1_chain_dists}a), the index also stores each boundary node's ``loop distance''.
The loop distance is the minimum distance to leave a boundary node, change direction in the chain, and return to the same node side traversing in the opposite direction.
These loop distances are stored in final two arrays, one for each direction.
In Figure~\ref{fig:aim1_chain_dists}a, the forward loop distance for node $C$ is two times the length of $E$: the distance to leave $\bar{c}$ traversing forward and return to $\bar{c}$ traversing backward by taking the bold looping edge on $\bar{e}$.
These three arrays are sufficient to find the minimum distance between any two node sides in the chain in constant time (Figure~\ref{fig:aim1_chain_dists}).


Chains that are not top-level chains cannot form a closed cycle so any path that traverses a chain's boundary node going out of the chain must leave the chain.
Therefore any connectivity between the boundaries of the chain will be captured by the snarl index of the chain's parent.
The top-level chain may form a closed cycle where the start and end boundary nodes are the same node (Figure \ref{fig:aim1_cyclic_chain}).
In this case, the shortest path may remain within the chain, but it may also leave the chain and re-enter it from the other side.
In Figure \ref{fig:aim1_cyclic_chain}, the minimum distance from $\bar{a}$ to $d$ could be $d(\bar{a}, \bar{d}) + d(d, d)$ or $d(\bar{a}, \bar{a}) + d(a, d)$.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\columnwidth]{aim1_chain_dists.png}
    \caption[Chain distances]{
    (a) The shortest path between two nodes in a chain can sometimes reverse direction in the chain. The edges on the shortest path between the positions on $B$ and $D$ are bolded.
    (b) $A$ and $B$ are boundary nodes of snarls in a chain. Distances stored in the chain index are shown in black. For each boundary node in the chain, the chain index stores the minimum distance from the start of the chain to the left side of that node as well as the loop distances for a forward and backward traversal. These loop distances are the minimum distance to leave a node, reverse direction in the chain, and return to the same node side.
    (c) There are four possible minimum-distance paths between two nodes, connecting either node side of the two nodes. The lengths of these paths can be found using the distances stored in the chain index and the lengths of the nodes.}
    \label{fig:aim1_chain_dists}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.25\columnwidth]{aim1_cyclic_chain.png}
    \caption[Cyclic chain]{A cyclic chain containing two snarls, $(\bar{a}, \bar{d})$ and $(d, a)$  }
    \label{fig:aim1_cyclic_chain}
\end{figure}


\subsubsection{Index Construction}

The minimum distance index is constructed in a post-order traversal of the snarl tree.
For each snarl, the construction algorithm does a Dijkstra traversal starting from each child structure, using the child's index to find the distance to traverse child snarls or chains.
For each chain, the construction algorithm traverses through each snarl in the chain and uses the snarl's index to find each of the relevant distances for the chain index.

\subsubsection{Index Size}
Naively, a minimum distance index could store the minimum distance between every node in the graph.
A distance calculation would be a constant time lookup but the index size would be quadratic in the number of nodes in the graph.
For each snarl in the graph, our index stores the distance between every pair of structures in the net graph. For each chain, it stores three arrays, each the length of the chain. 
In a graph with a set of snarls $S$ and chains $C$, our index will take $O(\sum_Sn_s^2 + \sum_Cn_c)$ space where $n_s$ is the number of structures in the netgraph of snarl $s$ and $n_c$ is the number of snarls in chain $c$.


\subsection{Minimum Distance Algorithm}

The first step of our minimum distance algorithm (Algorithm \ref{alg:aim1_min_dist}) is to find the least common ancestor structure in the snarl tree that contains both positions. 
We do this by traversing up the snarl tree from each position and finding the first common structure.
This traversal is $O(d)$ where $d$ is the depth of the snarl tree.

Next, the algorithm finds the distance from each position to the ends of the child of the least common ancestor (Algorithm \ref{alg:aim1_dist_ancestsor}).
Starting at a position on a node, we find the distances to the ends of the node.
If both positions are oriented forward, then we find the distance to the right side of the fist node and the left side of the second, and we record the distances to the opposite sides as infinite.
In the case where a position is oriented backward, we find the distance to the opposite side.
The algorithm then traverses up the snarl tree to the least common ancestor and at each structure, finds the minimum distances to the ends of the structure.
Because of the split distance property, this distance can be found by adding the distances to the ends of the child, found in the previous step in the traversal, to the distances from the child to the boundary nodes of the structure, found using the minimum distance index (Figure \ref{fig:aim1_distance_parent}).
Since this requires only four constant-time queries to the minimum distance index, each step in the traversal is constant time and the overall traversal is $O(d)$.

At this point in the algorithm, we know the minimum distance from each position to its ancestor structure that is a child of the common ancestor.
By composing these distances with the distances between the two structures, the algorithm finds possible distances between the two positions in the common ancestor structure.
The algorithm continues to traverse the snarl tree up to the root and finds a minimum distance between the positions at each structure, checking for paths that leave the lowest common ancestor.
This traversal is also $O(d)$.
The minimum distance algorithm is done in three $O(d)$ traversals of the snarl tree, so the algorithm is $O(d)$.
In variation graphs for moderately large genomes without extreme levels of polymorphism, snarl trees are very shallow.
In these graphs, the algorithm is expected to be O(1). However, for variation graphs of small, highly polymorphic genomes, the run time may grow with increasing amounts of population variation.
Complex sequence graphs derived from assembly graphs also may demonstrate slower run time behavior.


\begin{table}[H]
    \centering
    \caption[Primitive functions for the minimum distance algorithm]{Primitive functions for the minimum distance algorithm}
    \label{tab:aim1_min_functions}
    \begin{tabularx}{\columnwidth}{|p{120pt}|X|p{70pt}|}
        \hline
         Function & Description & Complexity  \\
         \hline
         distToEndsOfParent( $struct$,$dist\_left$, $dist\_right)$ & Given the distances from a position in a structure $struct$ to the ends of $struct$, find the distance to the ends of the parent (Figure \ref{fig:aim1_distance_parent}) &$O(1)$ using the distance index\\
         distWithinStructure( $struct$, $child\_1$, $child\_2$, $dist1\_l$, $dist1\_r$, $dist2\_l$, $dist2\_r)$  & Given two children of a structure and distances from positions to the boundaries of the children, find the minimum distance between the positions in $struct$ & $O(1)$ using the distance index\\

         \hline
    \end{tabularx}
\end{table}

\begin{figure}[H]
\centering
    \includegraphics[width=0.5\columnwidth]{aim1_distance_parent.png}
    \caption[Distance to ends of parent calculation]{
    The distToEndsOfParent calculation described in Table \ref{tab:aim1_min_functions}.
    (a) $S$ and $E$ are the boundary nodes of a structure that contains a child structure $N$. The minimum distances from some object in $N$ to the ends of $N$ shown as black arrows.
    (b) The minimum distances from each end of $N$ to $\bar{s}$ and $e$ are found using the minimum distance index.
    (c) By adding the appropriate distances and taking the minimums, we can get the minimum distances to $s$ and $\bar{e}$.
    }
    \label{fig:aim1_distance_parent}
\end{figure}


\begin{algorithm}[H]
    \caption[Algorithm for finding the distance from a position to the bounds of an ancestor snarl or chain]{distToAncestor($position$, $ancestor$): Given a position and ancestor structure, return the minimum distance from the position to both sides of a child of the ancestor and the child}
    \Begin{
    $struct \longleftarrow$ parentOf($position$)\\
	$dist\_l, dist\_r \longleftarrow $ distances from $position$ to ends of node, one is $\infty$\\
    \While{\upshape{parentOf}($struct$) \upshape{ is not }$ancestor$}	{
	    \tcc{Find the minimum distance from $position$ to the boundaries of each ancestor}

		$dist\_l, dist\_r \longleftarrow$ distToEndsOfParent($struct, dist\_l, dist\_r$)\\

		$struct \longleftarrow$ parentOf$(struct)$\\
	}
    \Return $dist\_l, dist\_r, struct$
    }
    \label{alg:aim1_dist_ancestsor}
\end{algorithm}

\begin{algorithm}[H]
	\caption[Algorithm for finding the minimum distance between two positions in a variation graph]{minDistance($position\_1, position\_2$): Return the minimum distance from $position\_1$ to $position\_2$, $\infty$ if no path between them exists}
	\Begin{
	\tcc{Get distances from each position to the ends of a child of the least common ancestor}
	$ancestor \longleftarrow$ leastCommonAncestor$(position\_1, position\_2)$\\
	$dist1\_l, dist1\_r, struct\_1 \longleftarrow $ distToAncestor($position\_1, ancestor$)\\
	$dist2\_l, dist2\_r, struct\_2 \longleftarrow $ distToAncestor($position\_2, ancestor$)\\

	$min\_dist \longleftarrow \infty$\\
	\While {$ancestor$ \upshape{ is not } $root\ of\ snarl\ tree$}{
	    \tcc{Given the distance from each position to both sides of a child of $ancestor$, find the minimum distance between the two positions in $ancestor$}

	    $min\_dist \longleftarrow$ min($min\_dist, $distWithinStructure$(ancestor$, $struct\_1$, $struct\_2$, $dist1\_l$, $dist1\_r$, $dist2\_l$, $dist2\_r))$\\


	    $dist1\_l, dist1\_r \longleftarrow$ distToEndsOfParent$(struct\_1, dist1\_l, dist1\_r)$\\
	    $dist2\_l, dist2\_r \longleftarrow$ distToEndsOfParent$(struct\_2, dist2\_l, dist2\_r)$\\

	    $struct\_1 \longleftarrow ancestor$, $struct\_2 \longleftarrow ancestor$\\
	    $ancestor \longleftarrow$ parentOf$(ancestor)$
	}
	\Return $min\_dist$
	}
	\label{alg:aim1_min_dist}
\end{algorithm}

\section{Clustering}
Seed-and-extend algorithms sometimes cluster seed alignments by their location in the graph to find which might belong to the same mapping. 
Using our minimum distance index, we developed an algorithm to cluster positions based on the minimum distance between them in the graph.

\subsection{Problem}
We will cluster seeds by partitioning them based on the minimum distance between their positions in a sequence graph. 
To define a cluster, we consider a graph where each seed is a node and two seeds are connected if the minimum distance between their positions is less than a given distance limit. 
In this graph, each connected component is a cluster.

    
\subsection{Algorithm}


Our clustering algorithm starts with each position in a separate cluster then progressively agglomerates the clusters (Figure \ref{fig:aim1_cluster_example}).
The algorithm proceeds in a post-order traversal of the snarl tree and, at each structure, produces clusters of all positions contained in that structure (Algorithm \ref{alg:cluster}).
After iterating over a structure, clusters are also annotated with two ``boundary distances'': the shortest distance from any of its positions to the boundary nodes of the structure.
At every iteration, each cluster can be unambiguously identified with a structure and so the boundary distances are always measured to the structure the cluster is on.

The method of agglomerating clusters and computing boundary distances vary according to the type of structure.
For nodes, the algorithm creates a sorted array of the positions contained in it and splits the array into separate clusters when the distance between successive positions is large enough.
For each new cluster, the boundary distances are computed from the positions' offsets.


For structures that are snarls or chains, clusters are created from the clusters on their children (Algorithm \ref{alg:cluster_snarl}, Algorithm \ref{alg:cluster_chain}).
Clusters associated with child structures are compared and if the distance between any pair of their positions is smaller than the  distance limit, they are combined.
Within a structure, distances to clusters that are associated with child structures can be calculated using the split distance property as in the minimum distance algorithm.
According to this property, the minimum distance can be split into the cluster's boundary distance and the distance to one of the boundary nodes, which is found using the index.
For snarls, all pairs of clusters are compared to each other.
For chains, clusters are combined in the order they occur in the chain, so each cluster is compared to agglomerated clusters that preceded it in the chain.
Finally, for each of the resulting clusters, we compute the boundary distances for the current structure, once again using the boundary distances of the children and the index.

In the worst case, every position would belong to a separate cluster and at every level of the snarl tree, every cluster would be compared to every other cluster.
This would be $O(dn^2)$ where $d$ is the depth of the snarl tree and $n$ is the number of seeds, so in the worst case our clustering algorithm is no better than the naive algorithm of comparing every pair of positions with our minimum distance algorithm.
In practice, however, seeds that came from the same alignment would be near each other on the graph and form clusters together, significantly reducing the number of distance comparisons that would be made.

\begin{figure}[H]
\centering
\includegraphics[width=\columnwidth]{aim1_cluster_example.png}
\caption[Clustering algorithm]{
Clustering of positions (Xs) is done by traversing up the snarl tree and progressively agglomerating clusters. Positions are colored by the final clusters.
(a) Each position starts out in a separate cluster on a node. Each cluster is annotated with its boundary distances: the minimum distances from any of its positions to the ends of the structure it is on.
(b) For each snarl on the lowest level of the snarl tree, the clusters on the snarl's children are agglomerated into new clusters on the snarl. The boundary distances are extended to the ends of the snarl.
(c) For each chain on the next level of the snarl tree, the clusters on the chain's snarls are agglomerated and the boundary distances are updated to reach the ends of the chain.
This process is repeated on each level of the snarl tree up to the root.}
  \label{fig:aim1_cluster_example}
\end{figure}


\begin{algorithm}[H]
    \caption[Algorithm for finding clusters of positions on a snarl]{clusterSnarl($snarl$, $child\_to\_clusters$, $distance\_limit$): Given a snarl and map from children of the snarl to their clusters, get clusters of the snarl}
    \Begin{
        $snarl\_clusters \longleftarrow$ \tcp{Array of all clusters in $child\_to\_clusters$}
        \For{$struct, cluster$ \upshape{in} $child\_to\_clusters$}{
            \tcc{Record the minimum distances from each cluster to the boundaries of $snarl$}
            $cluster.dist\_left\_parent, cluster.dist\_right\_parent \longleftarrow$ distToEndsOfParent$(struct, cluster.dist\_left, cluster.dist\_right)$
        }
        \For{$struct\_1, cluster\_1$ \upshape{in} $child\_to\_clusters$}{
            \For{$struct\_2, cluster\_2$ \upshape{in} $child\_to\_clusters$}{
                \tcc{Compare each pair of clusters and if they are close enough, combine them}
                $cluster\_dist \longleftarrow$ distWithinStructure$(snarl$, $struct\_1$, $struc\_2$, $cluster\_1.dist\_left$, $cluster\_1.dist\_right$, $cluster\_2.dist\_left$, $cluster\_2.dist\_right)$\\
                \If{$cluster\_dist \leq distance\_limit$}{
                    Agglomerate $cluster\_1$ and $cluster\_2$, take the minimum $dist\_left\_parent$ and $dist\_right\_parent$
                }
            }
        }
        \For{$cluster$ \upshape{in} $snarl\_clusters$} {
            \tcc{Update boundary distances to reach the ends of $snarl$}
            $cluster.dist\_left, cluster.dist\_right \longleftarrow cluster.dist\_left\_parent, cluster.dist\_right\_parent$
        }
        \Return $snarl\_clusters$
    }
    \label{alg:cluster_snarl}
\end{algorithm}

\begin{algorithm}[H]
    \caption[Algorithm for finding clusters of positions on a chain]{clusterChain($chain$, $child\_to\_clusters$, $distance\_limit$): Given a chain and a map from each snarl in the chain to its clusters, get clusters of the chain}
    \Begin{
        $chain\_clusters \longleftarrow []$\tcp{Empty array of clusters of $chain$}
        \For{$snarl, snarl\_cluster$ \upshape{in} $child\_to\_clusters$}{
            \tcc{Record the minimum distances from $snarl\_cluster$ to the boundaries of $chain$}
            $snarl\_cluster.dist\_left\_parent$, $snarl\_cluster.dist\_right\_parent \longleftarrow$ distToEndsOfParent$(snarl, cluster.dist\_left, dist\_right)$
            \For{$chain\_cluster$ \upshape{in} $chain\_clusters$}{
                \tcc{Compare the snarl clusters with each previously found chain cluster}
                \If{$chain\_cluster.distance\_right + snarl\_cluster.distance\_left \leq distance\_limit$}{
                    Agglomerate $snarl\_cluster$ and $chain\_cluster$, take the minimum $dist\_left\_parent$ and $dist\_right\_parent$
                }
            }
            \For{$cluster$ \upshape{in} $chain\_clusters$}{
                \tcc{Update the right distance of each cluster to reach the end of $snarl$}
                $cluster.dist\_right \longleftarrow cluster.dist\_right+snarl.length$
            }
            Add any uncombined snarl clusters to $chain\_clusters$
        }
        \Return $chain\_clusters$
    }
    \label{alg:cluster_chain}
\end{algorithm}

\begin{algorithm}[H]
\caption[Algorithm for finding clusters of positions on a graph]{cluster($snarl\_tree$, $positions$, $distance\_limit$): Cluster positions based on the distance limit}
\Begin{
    $struct\_to\_clusters$ \tcp{Map each structure to its clusters}
    \For{$struct$ in $snarl\_tree$}{
    \tcc{Traverse structures in post-order}
        \If{$struct$ \upshape{is a node}}{
            $struct\_to\_clusters[struct] \longleftarrow $ clusters of positions on $struct$
        }\ElseIf{ $struct$ \upshape{is a snarl} }{
            $child\_clusters \longleftarrow$ \tcp{Get map from each child of $struct$ to its clusters}
            $struct\_to\_clusters[struct] \longleftarrow $ clusterSnarl($struct$, $child\_clusters$, $distance\_limit$)
        }\Else{
            $child\_clusters \longleftarrow $\tcp{Get map from each child of $struct$ to its clusters}
            $struct\_to\_clusters[struct] \longleftarrow $ clusterChain($struct, child\_clusters,distance\_limit$)
        }
    }
    \Return $struct\_to\_clusters[snarl\_tree.root]$
}
\label{alg:cluster}
\end{algorithm}


\section{Methods and Results}

Our algorithms are implemented as part of the \texttt{vg} toolkit.
We conducted experiments on two different graphs: a human genome variation graph and a graph with simulated structural variants.
The human genome variation graph was constructed from GRCh37 and the variants from the 1000 Genomes Project.
The structural variant graph was simulated with $10$bp-$1$kbp insertions and deletions every $500$bp.

The human genome variation graph had $306,009,792$ nodes, $396,177,818$ edges, and $3,180,963,531$ bps of sequence.
The snarl tree for this graph had a maximum depth of three snarls with $139,418,023$ snarls and $11,941$ chains.
The minimum distance index for the graph was 12.2 GB on disk and 17.7 GB in memory.

To assess the run time of our minimum distance algorithm, we calculated distances between positions on the whole genome graph and compared the run time of our algorithm to \texttt{vg}'s path-based algorithm and Dijkstra's algorithm (Figure \ref{fig:aim1_distance_times}).
We chose random pairs of positions in two ways. The first method sampled positions uniformly at random throughout the graph.
The second method first followed a random walk of $148$ bp through the graph and then sampled two positions uniformly at random from this random walk.
This approach was intended to approximate the case of seeds from a next-generation sequencing read.
On average, our minimum distance algorithm is the fastest of the three algorithms for both sets of positions.
In addition, all three algorithms' performance degraded when the positions could be sampled arbitrarily far apart in the graph, but our minimum distance algorithm's performance degraded the least.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\columnwidth]{aim1_distance_times.png}
    \caption[Run times for distance algorithms]{\textbf{Run times for distance algorithms.}  Random pairs of positions were chosen from either within a read-length random walk (dark colors) or randomly from the graph (light colors).}
    \label{fig:aim1_distance_times}
\end{figure}

Our new minimum distance algorithm shows a distinct gain in performance over the other methods, however the algorithm must trade off speed with the memory consumed by the index.
A hybrid approach could be imagined where the index is used to compute the distance up structures in the common ancestor, then Dijkstra's algorithm could be used to connect the structures.
The runtime of such a hybrid algorithm is in the worst case the same as Dijkstra's algorithm.
Using this approach, the distance index would only need to store the distance from each node in a snarl to the boundary nodes of the snarl, rather than the distance between every pair of nodes, reducing the memory requirement of the index.

In the context of read mapping, we are often only interested in the exact distance when the minimum distance is small, but when the minimum distance is large enough the exact distance is not necessary.
In this scenario, the algorithm could be accelerated by stopping early when it is apparent that the minimum distance will be too large.



We used the structural variant graph to assess whether the minimum distance is a useful measure of distance for read mapping.
We compared our minimum distance algorithm to the path-based approximation, which estimates distances based on linear paths corresponding to scaffolds of a reference genome.
To do so, we again used read-length random walks to select pairs of positions.
Further, we filtered random walks down to those that overlapped a structural variant breakpoint.
We then calculated the distances between pairs of positions using our minimum distance algorithm and the path-based approximation and compared these distances to the actual distances in the random walk, which we take as an approximation of the true distance on a sequencing read.
Overall, the minimum distance was a much better estimate of distance along the random walk than the path-based distance approximation (Figure \ref{fig:aim1_sv_distances}).


\begin{figure}[H]
    \centering
    \includegraphics[width=\columnwidth]{aim1_sv_distances.png}
    \caption[Distance calculations on a graph with simulated structural variants]{\textbf{Distance calculations on a graph with simulated structural variants.} Read-length random walks were simulated near the junctions of structural variants. The distance between two random positions along each walk was calculated using the path-based method and our minimum distance algorithm and compared to the actual distance in the walk.}
    \label{fig:aim1_sv_distances}
\end{figure}

For our clustering algorithm, we wanted to estimate the run time of the algorithm in the context of read mapping. We simulated $148$bp reads from AshkenazimTrio HG002\_NA24385\_son from the Genome in a Bottle Consortium \cite{zook_extensive_2016}.
For each read, we sampled 15-mer matches from the read and found their positions in the human genome variation graph using a $k$-mer lookup table. We then apply the clustering algorithm to the positions of these $k$-mers.
The regression line of the log-log plot of run times suggests the run time of our algorithm is linear in the number of positions in practice, despite the quadratic worst-case bound (Figure \ref{fig:aim1_cluster_times}).

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\columnwidth]{aim1_cluster_times.png}
    \caption[Run time growth of clustering algorithm]{\textbf{Run time growth of our clustering algorithm.} The regression line suggests that the run time of our algorithm is approximately linear in the number of positions in practice.}
    \label{fig:aim1_cluster_times}
\end{figure}

\section{Conclusion}
Pangenomes have the potential to eliminate reference bias and grow the inclusiveness of reference structures used in genomics, but substantial algorithmic challenges remain in adapting existing paradigms to use them.
We have developed a simple and elegant minimum distance algorithm with run time that is linear in the depth of the snarl tree.
In practice, the algorithm exploits the observation that real-world genome graphs have an excess of small, local variations and relatively fewer variations that connect disparate parts of the graph.
The result is that real genome graphs have a shallow snarl tree, making the calculations fast and effectively constant time in practice; indeed, we observe the algorithm is substantially faster than other distance algorithms on queries of arbitrary distance.
The minimum distance we return is an exact distance, unlike the previous heuristic implementation of distance in \texttt{vg}, resulting in much more reasonable estimates of distance around the breakpoints of structural variants.
Our minimum distance algorithm will also work with any sequence graph, whereas the preexisting \texttt{vg} distance algorithm required pre-specified paths.
Here we developed a clustering algorithm for clustering positions on the graph based on the minimum distances between them.
Clustering is a major component of many mapping algorithms and calculating distance is a bottleneck of clustering in genome graphs.
Our new clustering algorithm runs in linear time relative to the number of seeds, whereas many existing algorithms, including the current vg mapper’s path-based algorithm, are (at least) quadratic due to pairwise distance calculations between seeds.
We believe this is an important step in generalizing efficient mapping algorithms to work with genome graphs; we are now developing fast mapping algorithms that use this clustering algorithm.


\section{Funding}
This work was supported, in part, by the National Institutes of Health (award numbers: 5U54HG007990, 5T32HG008345-04, 1U01HL137183, R01HG010053, U01HL137183, 2U41HG007234).

\chapter{Short read mapping}
\label{chapter:sr-giraffe}
\section{Preface}
This chapter contains the full text of the paper "Pangenomics enables genotyping of known structural variants in $5202$ diverse genomes"\cite{sr_giraffe_2021}, published in Science in 2021.
The portions of the paper's supplement that describe or are pertinent to my contributions can be found in the Appendix, Section \ref{sec:appendix_sr_giraffe}.
The remainder of the supplement referenced by the main text can be found in the online supplement of the paper.
The text contains minor edits to conform with the format of this thesis.

I was a co-first author along with Jouni Sirén, Jean Monlong, Adam M. Novak, and Jordan M. Eizenga.
Jouni Sirén, Adam M. Novak, and I did the majority of the software development of Giraffe.
I integrated the distance index and clustering algorithm from the previous chapter into the Giraffe implementation, adapted the single end algorithm to paired-end mapping, contributed to the paired-end rescue implementation, and contributed to the overall software development and optimization of the Giraffe tool.
Jouni Sirén implemented the GBWT data structure and related algorithms including the minimizer index, seeding, haplotype sampling, and gapless extension.
Adam M. Novak integrated the components of Giraffe into the full working tool, built the graphs for evaluations, and contributed to the optimization of Giraffe.
Jordan M. Eizenga wrote the alignment algorithms and mapping quality code that Giraffe uses.
Jean Monlong performed all the structural variant analyses.
I performed the simulated read mapping experiments, runtime and memory analyses, and reference bias analyses. 
Charlie Markello performed the short variant calling analyses.
Jonas A. Sibbesen built the indexes for and ran HISAT2.
Glenn Hickey contributed to the structural variant analyses and built the yeast graph.
Jouni Sirén, Jean Monlong, Adam M. Novak, and I wrote the majority of the paper. 

\newpage

\section{Structured abstract}

\noindent
\textbf{Introduction}

Modern genomics depends on inexpensive short-read sequencing.
Sequenced reads up to a few hundred base pairs in length are computationally mapped to estimated source locations in a reference genome.
These read mappings are used in myriad sequencing-based assays.
For example, through a process called genotyping, mapped reads from a DNA sample can be used to infer the combination of alleles present at each site in the reference genome.

\noindent
\textbf{Rationale}

A single reference genome cannot capture the diversity within even a single person (who gets a genome copy from each parent), let alone in the whole human population.
Genomes differ not only by point variations, where one or a few bases are different, but also by structural variations, where differences can be much larger than an individual read.
When a person’s genome differs from the reference by a structural variation, the reference may contain no location to correctly map the corresponding reads.
Although newer long-read sequencing allows structural variation to be more directly observed in sequencing reads, short-read sequencing is still less expensive and more widely available.

\noindent
\textbf{Results}

We present a short read–mapping tool, Giraffe.
Giraffe maps to a pangenome reference that describes many genomes and the differences between them.
Giraffe can accurately map reads to thousands of genomes embedded in a pangenome reference as quickly as existing tools map to a single reference genome.
Simulations in which the true mapping for each read is known show that Giraffe is as accurate as the most accurate previously published tool.
Giraffe achieves this speed and accuracy by using a variety of algorithmic techniques.
In particular, and in contrast to previous tools, it focuses on mapping to the paths in the pangenome that are observed in individuals’ genomes: the reference haplotypes.
This has two key benefits.
First, it prioritizes alignments that are consistent with known sequences, avoiding combinations of alleles that are biologically unlikely.
Second, it reduces the size of the problem by limiting the sequence space to which the reads could be aligned.
This deals effectively with complex graph regions where most paths represent rare or nonexistent sequences.

Using Giraffe in place of a single reference genome reduces mapping bias, which is the tendency to incorrectly map reads that differ from the reference genome.
Combining Giraffe with state-of-the-art genotyping algorithms demonstrates that Giraffe mappings produce accurate genotyping results.

Using mappings from Giraffe, we genotyped $167,000$ recently discovered structural variations in short-read samples for $5202$ people at an average computational cost of \$1.50 per sample.
We present estimates for the frequency of different versions of these structural variations in the human population as a whole and within individual subpopulations.
We identify thousands of these structural variations as expression quantitative trait loci (eQTLs), which are associated with gene-expression levels.

\noindent
\textbf{Conclusion}

Giraffe demonstrates the practicality of a pangenomic approach to short-read mapping.
This approach allows short-read data to genotype single-nucleotide variations, short insertions and deletions, and structural variations more accurately.
For structural variations, this allowed the estimation of population frequencies across a diverse cohort of 5000 individuals.
A single reference genome must choose one version of any variation to represent, leaving the other versions unrepresented.
By making more broadly representative pangenome references practical, Giraffe attempts to make genomics more inclusive.

\section{Abstract}
We introduce Giraffe, a pangenome short-read mapper that can efficiently map to a collection of haplotypes threaded through a sequence graph.
Giraffe maps sequencing reads to thousands of human genomes at a speed comparable to that of standard methods mapping to a single reference genome.
The increased mapping accuracy enables downstream improvements in genome-wide genotyping pipelines for both small variants and larger structural variants.
We used Giraffe to genotype 167,000 structural variants, discovered in long-read studies, in 5202 diverse human genomes that were sequenced using short reads.
We conclude that pangenomics facilitates a more comprehensive characterization of variation and, as a result, has the potential to improve many genomic analyses.

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{aim2_summary.pdf}
    \caption[Overview of short read giraffe experiments]{\textbf{Overview of the experiments} Variant calls from long read–based and large-scale sequencing studies were used to construct pangenome reference graphs (top). Giraffe (and competing mappers) mapped reads to the graph or to linear references, and mapping accuracy, allele coverage balance, and speed were evaluated (middle). Then, mapped reads were used for variant calling, and variant call accuracy was evaluated (bottom). Structural variant calls were analyzed alongside expression data to identify eQTLs and population frequency estimates.}
    \label{fig:aim2_summary}
\end{figure}

\section{Introduction}
The field of genomics almost exclusively uses a single reference genome assembly as an archetype of a human genome.
Reliance on comparing with the sequences within the reference assembly has created a pervasive bias toward the alleles it contains.
This reference allele bias occurs because nonreference alleles are naturally harder to identify when mapping DNA sequencing data to the reference sequences.
Reference allele bias is particularly acute for structural variations (SVs), which are complex alleles involving 50 or more nucleotides of divergent sequence.
SVs affect millions of bases within each human genome.
Because of reference allele bias, SVs are much more poorly characterized than single-nucleotide variants (SNVs) and short insertions and deletions (collectively termed indels)\cite{zook_robust_2020,mahmoud_structural_2019}.
Similarly, characterizing genetic variation in highly polymorphic and repetitive sequences has proven challenging \cite{ebler_genotyping_2017}.

Recent releases of the reference human genome assembly attempted to address these issues by adding additional sequences.
These alternate sequences represent diversity in localized regions of the genome \cite{church_modernizing_2011}.
However, to date, these limited additions have not found widespread use. By contrast, pangenomes encode information about many complete genome assemblies and their homologies (the sequences that are shared between genomes by virtue of descending from a common ancestral sequence).
Pangenomes are emerging as a replacement for linear reference assemblies to help mitigate these problems \cite{noauthor_computational_2016,sherman_pan-genomics_2020,ballouz_is_2019}.
They can particularly improve genotyping of structural variants\cite{hickey_vgsv_2020}.

Pangenomes are frequently formulated as sequence graphs\cite{eizenga_pangenome_2020}—mathematical graphs that represent the homology relationships between multiple sequences.
Several algorithms have been developed for mapping sequences to sequence graphs.
None has yet made mapping the short sequencing reads from widely used DNA sequencers, such as those made by Illumina, to a structurally complex pangenome a practical option for large-scale applications.
The original VG-MAP algorithm\cite{garrison_variation_2018} maps to complex sequence graphs that contain cycles produced by duplications and complex genomic rearrangements\cite{garrison_variation_2018}.
However, VG-MAP is at least an order of magnitude slower than popular linear genome mappers that have comparable accuracy.
Given that mapping is frequently a bottleneck in genome analysis, the cost of VG-MAP has proven prohibitive. Other pangenome mappers have different capabilities and limitations.
Some are faster but are limited to acyclic graphs that contain variation at relatively low density\cite{kim_hisat2_2019}, and some can map to arbitrary sequence graphs but are designed for long reads\cite{rautiainen_graphaligner_2020}. Other tools are not open source and are thus unavailable for general testing and customization\cite{sevenbridges_2019,illumina_dragen_2019}, and some additionally cannot run on commodity computing environments\cite{illumina_dragen_2019}.

\section{Results}
\subsection{Giraffe: Fast, haplotype-aware pangenome mapping}
When a sequence graph reference\cite{noauthor_computational_2016} (Figure \ref{fig:aim2_supplement_graph-example}) is substituted for the traditional linear reference (Figure \ref{fig:aim2_fig1} A), it can reduce reference allele bias by including more alleles\cite{garrison_variation_2018}. 
However, it also expands the size of the alignment search space from a few linear chromosome strings to a combinatorially large number of paths in the graph.
This has made our previous graph mappers slower than linear mappers\cite{garrison_variation_2018}.
Giraffe solves this problem by considering the paths that are observed in individuals’ genomes: the reference haplotypes.
We use the two haplotypes (one from each parent) that each individual has in their genome and trace them as paths through the sequence graph.
The graph describes which positions in the haplotypes are equivalent, whereas the haplotypes describe the subset of the possible paths in the graph to consider.
Giraffe uses a graph Burrows-Wheeler transform (GBWT) index\cite{siren_indexes_2020} to store and query a graph’s haplotypes efficiently.

Giraffe’s strategy of aligning to haplotype paths has two key benefits.
First, it prioritizes alignments that are consistent with known sequences, thereby avoiding combinations of alleles that are biologically unlikely.
Second, it reduces the size of the problem by limiting the sequence space to which the reads could be aligned.
This deals effectively with complex graph regions where most paths represent rare or nonexistent sequences.

We designed Giraffe to minimize the amount of gapped alignment that is performed.
Computing gapped alignments, in which sequences are allowed to gain or lose bases relative to each other, is much more expensive than gapless alignment because it requires pairwise dynamic programming algorithms.
Most Illumina sequencing errors are substitutions\cite{schirmer2016illumina}, and common true indels relative to the traditional linear reference should already be present in the haplotypes; therefore, almost all reads will have a gapless alignment to some stored haplotype.
Hence, we try to align each read without gaps before resorting to dynamic programming.

Giraffe follows the common seed-and-extend approach used by most existing mappers (Section \ref{subsec:aim2:giraffe-methods}.
In this framework, short seed matches between a sequencing read and a genomic reference are found with minimal work, and then only good seeds are extended into mappings of the entire read \cite{langmead_bowtie2_2012,li_bwa_mem_2013,li_minimap2_2018}.
A visual overview of Giraffe’s operation is given in (Figure \ref{fig:aim2_fig1}, B to F).
The Giraffe algorithm uses several heuristics for prioritizing alignments.
These heuristics are configurable, and we present two presets: default Giraffe (written as just “Giraffe”) balances speed and accuracy, and fast Giraffe optimizes for speed at the expense of some accuracy.
\begin{figure}
    \centering
    \includegraphics[width=.5\linewidth]{aim2_fig1.pdf}
    \caption[Haplotype mapping]{\textbf{Haplotype mapping.} (A) A region of the CASP12 gene in the 1000GP graph, illustrating complex local variation. The observed haplotypes (the colored ribbons of width log-proportional to population frequency) represent only a subset of the possible paths through the graph. (B to F) An overview of Giraffe. Input structures are shown in (B): Giraffe takes as input each read to map, the sequence graph reference to map against, and the GBWT of known haplotypes to restrict to. The input read is represented as a series of colored rectangles. The haplotype sequences in the GBWT are similarly represented as series of rectangles, split according to the nodes they correspond to in the sequence graph. Nodes in the sequence graph and haplotypes in the GBWT are colored according to homology with the read. Haplotype minimizer seeding is shown in (C): Seeds are identified using an index of minimizers (subsets of sequences of specified length k)\cite{Roberts2004} over the sequences of all the GBWT haplotypes. A matching minimizer between the read and the GBWT haplotypes constitutes a seed. The minimizers (black boxes) in the read are enumerated and the matching minimizers in the haplotypes are identified using the minimizer index. Seed clustering is shown in (D): Minimizer instances in the graph are clustered by the minimum graph distance (t, measured in nucleotides) between them\cite{chang_distance_2020}. Seed extension along haplotypes is shown in (E): Minimizers in high-scoring clusters are extended linearly to form maximal gapless local alignments. Haplotype-restricted gapped alignment is shown in (F): Giraffe is designed on the assumption that for most reads, it will be possible to gaplessly extend seed alignments all the way to the ends of the read, allowing the algorithm to stop at the previous step. However, any remaining gaps in the alignment between read and graph are resolved by gapped alignment in this final step.}
    \label{fig:aim2_fig1}
\end{figure}

\subsection{Pangenome references for evaluation}
To evaluate Giraffe, we built two human genome reference graphs based on the GRCh38 reference assembly.
One (the 1000GP graph) contained mostly small [<50 base pairs (bp)] variants from the 1000 Genomes Project \cite{1000gp_2015}.
The other (the HGSVC graph) contained entirely SVs ($\geq$50 bp) from the Human Genome Structural Variant Consortium\cite{chaisson_sv_2019}.
The 1000GP graph contained data from 2503 individuals, with one (NA19239) held out for benchmarking.
It was built from 76,749,431 SNVs; 3,177,111 small indels (<50 bp); and 181 larger SVs ($/geq$50 bp).
The HGSVC graph contained data from three individuals sequenced with long reads: HG00514, HG00733, and NA19240.
The HGSVC graph contained 78,106 larger SVs ($\leq$50 bp). Both graphs are available for reuse (see Data and materials availability in the Acknowledgments).

\subsection{Giraffe and VG-MAP map accurately to human pangenomes}
We evaluated Giraffe for mapping human data by simulating paired-end reads for two individuals (Section \ref{subsec:aim2:readsim}): NA19240, who has available genotypes for the HGSVC variants \cite{chaisson_sv_2019}, and NA19239, who has available genotypes for the 1000GP variants\cite{1000gp_2015}.
Simulated read sets were mapped using Giraffe and competing tools (Section \ref{subsec:aim2:readmapping}).
We examined the accuracy of single- and paired-end mapping (Figure \ref{fig:aim2_fig2}).
We looked at a variety of input read sets and evaluated the calibration of reported mapping quality, which is a standard measure of mapping uncertainty (Figures.\ref{fig:aim2_supplement_novaseq_rocs},\ref{fig:aim2_supplement_hiseqxten_rocs},\ref{fig:aim2_supplement_hiseq2500_rocs},\ref{fig:aim2_supplement_novaseq6000_qq},\ref{fig:aim2_supplement_hiseqxten_qq},\ref{fig:aim2_supplement_hiseq2500_qq} and Tables \ref{tab:mapping_accuracy_1kg_novaseq6000},\ref{tab:mapping_accuracy_1kg_hiseqxten},\ref{tab:mapping_accuracy_1kg_hiseq2500},\ref{tab:mapping_accuracy_hgsvc_novaseq6000},\ref{tab:mapping_accuracy_hgsvc_hiseqxten},\ref{tab:mapping_accuracy_hgsvc_hiseq2500}).
Relative to other tools, at the highest reported mapping quality, VG-MAP and default Giraffe consistently have either higher precision or higher recall across all simulated read technologies and graphs.
Their performance is generally similar.
Relative to the linear mappers, the Giraffe and VG-MAP lead is larger for the HGSVC graph (Figure \ref{fig:aim2_fig2}, C and D) than for the 1000GP graph (Figure \ref{fig:aim2_fig2}, A and B).
This suggests that the gains from using a genome graph are higher when the graph facilitates alignment of genomic sequences from the sample that differ greatly from the linear reference.
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{aim2_fig2.pdf}
    \caption[Simulated read mapping]{\textbf{Simulated read mapping} (A to F) Each panel shows recall versus false discovery rate (or 1 minus precision) for a simulated read-mapping experiment, comparing Giraffe with linear genome mappers (BWA-MEM, Bowtie2, and Minimap2) and other genome graph mappers (VG-MAP, GraphAligner, and HISAT2). Reads were simulated to match $\sim150$-bp Illumina NovaSeq (for human) or HiSeq 2500 (for yeast) reads, either as single-end reads [(A) to (C)] or as paired-end reads [(D) to (F)] (Section \ref{subsec:aim2:readsim}). Results for each mapper are shown stratified by reported read-mapping quality; the size of each point represents the log-scaled number of reads with the corresponding mapping quality. Three different mapping scenarios are assessed: [(A) and (D)] Comparing mapping to a graph derived from the 1000GP data to mapping to the linear reference genome assembly upon which it is based (GRCh38); [(B) and (E)] comparing mapping to a graph containing larger structural variants from the HGSVC project to mapping to the GRCh38 assembly upon which it is based; and [(C) and (F)] comparing mapping to a multiple sequence alignment–based yeast graph to mapping to the single S.c. S288C linear reference, for reads from the DBVPG6044 strain. For mapping with Giraffe, we used the full GBWT that contains six haplotypes to map to the HGSVC graph and the 64-haplotype sampled GBWT to map to the 1000GP graph. “Giraffe primary” represents mapping with Giraffe to the linear reference.}
    \label{fig:aim2_fig2}
\end{figure}

\subsection{Haplotype sampling improves read mapping}
Having rare variants or errors in the graph and haplotypes may reduce mapping accuracy by creating opportunities for false-positive mappings\cite{Pritt2018}.
Mapping reads to regions with many distinct local haplotypes can also be slow.
Additionally, Giraffe needs a mechanism to synthesize haplotypes for graph components where no haplotype variation is known.
To overcome these issues, Giraffe includes mechanisms for creating synthetic haplotype paths.
When real haplotypes are available, these synthetic haplotype paths represent local haplotype variation sampled according to haplotype frequency, and we call the result a sampled GBWT (Section~\ref{subsec:aim2:downsampling}).
When no haplotypes are available, we call the result a path cover GBWT.
In this case, the synthetic haplotypes represent random walks through the graph. We evaluated the effects of running our mapping evaluations with sampled and path cover GBWTs (Figure \ref{fig:aim2_supplement_haplotype_sampling} and Tables \ref{tab:mapping_accuracy_1000gp_sampled_gbwt} and \ref{tab:mapping_accuracy_hgsvc_cover_gbwt}; Section~\ref{subsec:aim2:downsamplingeval}).
The mapping benefit of sampling more haplotypes plateaued at 64 haplotypes for the 1000GP graph (which contains around 5000 haplotypes), with higher accuracy than that achieved by mapping to the full haplotype set.
We used the HGSVC graph (which contains just six haplotypes) for an experiment on generating path covers without known haplotypes.
Path covers alone did not outperform the full underlying haplotype set for the HGSVC graph but came close to matching its performance.
We selected the 64-haplotype sampled GBWT for the 1000GP graph and the full GBWT for the HGSVC graph as the best-performing GBWTs, which we use in the rest of the analysis.

\subsection{Giraffe improves pangenome mapping speed}
We measured the runtime (Figure \ref{fig:aim2_fig3}, A and B) and memory usage (Figure \ref{fig:aim2_fig3}, C and D) of Giraffe and competing tools when mapping real reads (Section \ref{subsec:aim2:srgiraffe_speed}).
Giraffe was more than an order of magnitude faster than VG-MAP in all conditions.
It was also faster at aligning to human graphs than Bowtie2 or BWA-MEM were at aligning to the corresponding linear reference.
For the 1000GP graph, using the 64-haplotype sampled GBWT for mapping instead of the full $\sim$5000-haplotype GBWT was much faster in every case.
HISAT2 and fast Giraffe were both about equally fast and were both faster than all other mappers.

Because of the in-memory indexes it uses, Giraffe’s memory consumption is higher than the other mappers, except for GraphAligner.
However, it can map to the 1000GP graph with the full GBWT in $\sim$80 gigabytes (GB) of memory—an amount readily available on compute cluster nodes (Figure \ref{fig:aim2_fig3}, C and D).

\begin{figure}
    \centering
    \includegraphics[width=.8\linewidth]{aim2_fig3.pdf}
    \caption[Runtime and memory usage]{\textbf{Runtime and memory usage} (A to D) Total runtime [(A) and (B)] and peak memory use [(C) and (D)] for mapping $\sim$600 million NovaSeq 6000 reads using 16 threads. Reads were mapped [(A) and (C)] to the 1000GP derived graph or (for linear mappers) the GRCH38 assembly and [(B) and (D)] to the HGSVC graph or GRCh38 reference, respectively. For HISAT2*, results are shown for the subset 1000GP graph. “Giraffe full” refers to mapping using the full GBWT of all haplotypes. “Giraffe sampled” refers to mapping using the 64-haplotype sampled GBWT.}
    \label{fig:aim2_fig3}
\end{figure}

\subsection{Giraffe reduces allele mapping bias}
We assessed Giraffe’s reference bias (Section \ref{subsec:aim2:srgiraffe_allelebias}).
We expected Giraffe to be able to use the extra variation information contained in the graph reference to achieve a lower level of bias than a linear mapper.
For variants that were heterozygous in NA19239, we found the fraction of reads supporting alternate versus reference alleles at each indel length (Figure \ref{fig:aim2_fig4} A).
Giraffe and VG-MAP both show less bias toward the reference allele than a linear mapper, and this difference becomes more pronounced as indel length increases, particularly for larger insertions.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{aim2_fig4.pdf}
    \caption[Evaluating Giraffe for genotyping]{\textbf{Evaluating Giraffe for genotyping.} (A) The fraction of alternate alleles in reads detected for heterozygous variants in NA19239. Reads were mapped to the 1000GP graph with Giraffe and VG-MAP and to GRCh38 with BWA-MEM, and the fraction of reads supporting reference or alternate alleles was found for each indel length. (B) Assessing true-positive and false-positive genotypes made using the Dragen genotyper with mappings from Giraffe and other mappers. The line labeled Dragen represents the mapper included with the Dragen system itself. (C) Comparing Giraffe with VG-MAP for typing large insertions and deletions. “Presence” (lighter bars) evaluates the detection of SVs without regard to genotype; “genotype” (darker bars) requires the SV to be detected and its genotype to agree with the truth genotype. The y axis shows the F1 score. For the HGSVC benchmark, we define high-confidence regions as regions not overlapping simple repeats and segmental duplications. For the GIAB benchmark, we use the set high-confidence regions provided by GIAB.}
    \label{fig:aim2_fig4}
\end{figure}

\subsection{Giraffe genotyping outperforms best practices}
We used Illumina’s Dragen platform \cite{illumina_dragen_2019} to genotype SNVs and short indels using Giraffe mappings to the 1000GP graph, projected onto the linear reference assembly.
We compared these results with results using competing graph and linear reference mappers (Section \ref{subsec:aim2:dragen}).
No training or optimization was performed for any of the mappings other than those performed by default by Dragen itself. We evaluated the calls using the Genome in a Bottle (GIAB) v4.2.1 HG002 high-confidence variant-calling benchmark \cite{wagner_benchmarking_2020}.

Out of the examined pipelines, Giraffe mappings to the 1000GP graph produce the highest overall F1 score (harmonic mean of precision and recall) at 0.9953 (Figure \ref{fig:aim2_fig4}B and Tables \ref{tab:vcfeval_high_conf_2x150_hg002_grch38}, \ref{tab:happy_high_conf_2x150_hg002_grch38}).
Similar but uniformly higher results were found with higher-coverage, 250-bp reads (Figure \ref{fig:250bp_genotyping}, Tables \ref{tab:vcfeval_high_conf_2x250_hg002_grch38}, \ref{tab:happy_high_conf_2x250_hg002_grch38}).
Although one would expect longer reads and higher coverage to produce better variant calls, with all else being equal, Giraffe has a slightly higher F1 score with the 150-bp read set (0.9953) than BWA-MEM with the higher coverage 250-bp read set (0.9952).
Restricting comparison only to confident regions that overlap variant calls from the 1000GP variants used in graph construction, Giraffe has the highest F1 score at 0.9995 relative to the other methods (Table~\ref*{tab:vcfeval_high_conf_1000GP_only_2x150_hg002_grch38} and Figure~\ref*{fig:150bp_genotyping_1000GP_only}).
Perhaps surprisingly, Giraffe maintains the highest F1 score (0.9528) when performing the converse analysis, restricting the comparison to confident regions that do not overlap 1000GP variant calls (Table~\ref*{tab:vcfeval_high_conf_1000GP_excluded_2x150_hg002_grch38} and Figure~\ref*{fig:150bp_genotyping_1000GP_excluded}).

DeepVariant is a highly accurate genotyping tool that requires training \cite{poplin_universal_2018}.
We trained DeepVariant to use Giraffe mappings and evaluated it on the held-out sample HG003 (see \ref{subsec:aim2:genotyping-accuracy-methods}).
We compared it with the Dragen pipelines tested and DeepVariant using BWA-MEM with the BWA-MEM trained model that the developers provide.
The Giraffe-DeepVariant pipeline (F1: 0.9965) outperforms all other tested pipelines (Tables~\ref*{tab:deepvariant_vcfeval_high_conf_2x150_50x_hg003_grch38}, \ref*{tab:deepvariant_happy_high_conf_2x150_50x_hg003_grch38} and Figure~\ref*{fig:trained_deepvariant_genotyping}).

Previously, when we used VG-MAP to map reads to SV pangenomes, we found it to perform better than other methods for SV genotyping \cite{hickey_vgsv_2020}.
We replicated that evaluation on the HGSVC and GIAB datasets \cite{zook_robust_2020,chaisson_sv_2019} to confirm that the quality of the SV genotypes from Giraffe was competitive (Section \ref{subsec:aim2:svgenotyping}).
We observed similar SV genotyping accuracy across SV types, genomic regions, and datasets (Figure \ref{fig:aim2_fig4} C). Of note, GraphTyper \cite{eggertsson2019}, which was published after our earlier benchmarking analysis \cite{hickey_vgsv_2020}, was also compared with vg as a variant caller but showed lower genotyping performance across SV types, genomic regions, and datasets  (Figure \ref{fig:graphtyper_eval}).

\subsection{Giraffe generalizes beyond human}
We assessed Giraffe’s performance mapping to a yeast pangenome for five strains of the Saccharomyces cerevisiae and Saccharomyces paradoxus yeasts (Section \ref{subsec:aim2:yeast-methods}).
This graph was substantially different from the human graphs.
It proved challenging because it contains the cycles and duplications typical of graphs generated from genome-wide alignments of more divergent sequences.
Using a graph decomposition technique \cite{paten_superbubbles_2018}, we find it contains 1,459,769 variant sites, four times the density of variation in the 1000GP graph.
Ninety of these sites are complex, meaning that they are not directed, not acyclic, or not free of internal source and sink nodes.

Mapping accuracy results for reads from the held-out S. cerevisiae DBVPG6044 strain are displayed in Figure \ref{fig:aim2_fig2}, E and F, for the single-end and paired-end reads, respectively.
Speed results for mapping real reads are presented in (Figure \ref{fig:speed_yeast}).
Neither HISAT2 nor GraphAligner could map reads to the yeast graph; in the case of HISAT2, this was because it cannot map to graphs containing cycles.
Giraffe is 28 times faster for paired-end mapping than the only other tool that could map to this graph, VG-MAP, while achieving similar accuracy.
Both graph mappers are much more accurate than the linear reference methods.
Moreover, the gap between the graph methods and the linear reference is even larger on this graph than in the HGSVC graph (Figure \ref{fig:aim2_fig2}, C and D).
This lends further support to the hypothesis that graph-mapping methods have the most benefit when facilitating alignment of genomic sequences that differ greatly from the reference, such as the sibling-subspecies-scale differences represented in the yeast graph.

\subsection{Genotyping the SVs of the 5202 samples}
Building on our previous work to genotype SVs \cite{hickey_vgsv_2020}, we demonstrate the value of Giraffe by performing population-scale genotyping of an expanded compendium of SVs in large cohorts of samples sequenced with short reads.
We built a comprehensive pangenome containing SVs that combines variants from three catalogs of SVs that were discovered using long-read sequencing \cite{zook_robust_2020,chaisson_sv_2019,audano_hgsvc}.
The combined catalog represents 16 samples from diverse human populations and is estimated to cover most of the common insertions and deletions in the human population \cite{audano_hgsvc}.
Near-duplicate versions of variants (i.e., SVs with slightly different breakpoints) are often present within and across SV catalogs.
A naïve integration of all these variants can lead to redundancy in the graph that can affect read mapping and variant genotyping.
We remapped sequencing data and integrated variants iteratively into the graph to progressively build a nonredundant, compact SV graph (Section \ref{subsec:aim2:svpangenome}).
The final SV graph was constructed from 123,785 SVs from the original catalogs: 53,663 deletions and 70,122 insertions.
Overall, the graph contained 26.2 Mbp of nonreference sequences in the form of insertions. Using a graph decomposition \cite{paten_superbubbles_2018}, we identified 228,405 subgraphs that represent variant sites.
Some of these correspond to smaller variants nested inside larger ones. After combining these cases, there were 96,644 non-nested, nonoverlapping SV subgraphs.

Compared with Hickey et al. \cite{hickey_vgsv_2020}, we used a graph containing more SVs and a more recent version of the vg toolkit (see Data and materials availability in the Acknowledgments), including the Giraffe mapper presented here. Our SV genotypes were as accurate as those in \cite{hickey_vgsv_2020}, if not more so (Figure \ref{fig:sv-wdl-graph}A-C).
Thanks to Giraffe and improvements in the variant calling approach, the genotyping workflow used about 12 times less compute on a sample sequenced at about 20× coverage.

SV genotyping was run using the NHLBI BioData Catalyst ecosystem \cite{bdc2020} (Figure \ref{fig:sv-wdl-graph}D).
We genotyped samples from the Multi-Ethnic Study of Atherosclerosis (MESA) cohort within the Trans-Omics for Precision Medicine (TOPMed) program.
The MESA cohort is a longitudinal cohort study consisting of 6814 participants at baseline (between the years 2000 and 2002).
Participants were ascertained from six sites in the United States and identified themselves as “Spanish/Hispanic/Latino” (22$\%$ at baseline) and/or “African American or Black” (28$\%$), “Chinese” (12$\%$), and “Caucasian or White” (39$\%$) \cite{mesa_2008}. Two-thousand samples from the MESA cohort \cite{mesa_2008} were selected, using a criterion to maximize the sample diversity (Section \ref{subsec:aim2:mesaselection}).
Using the graph described above and fast Giraffe, it took around 4 days to genotype 2000 samples from the MESA cohort.
We used the same workflow to genotype the 3202 diverse samples from the high-coverage 1000GP dataset \cite{1000gp_nygc_2021} in around 6 days.
On average, genotyping a sample took 194.4 central processing unit (CPU)–hours of compute and cost between $1.11 and $1.56 (Figure \ref{fig:sv-wdl-graph}D, Tables \ref{tab:svwdl-corehours} and \ref{tab:svwdl-task}).
The sequencing data were down-sampled in advance to $\sim$20× coverage to reduce compute costs.
Benchmarking indicates that this down-sampling has a minimal impact on the genotyping accuracy (Figure \ref{fig:sveval-depth}).



\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{aim2_fig5.pdf}
    \caption[SVs in the MESA cohort]{\textbf{SVs in the MESA cohort.} (A) Cumulative proportion of SV sites depending on the maximum number of alleles (x axis) in the site. DEL, deletion; INS, insertion. (B and C) Illustration of an insertion site with five alleles. The alleles differ by three nested indels as shown by the multiple sequence alignment of the inserted sequences represented in (B). Only one allele is frequent in the population (allele frequency of 0.27), as highlighted in (C). (D) Allele frequency distribution of the major allele for each SV site. The y axis, showing the number of SVs, is log-scaled. (E) Size distribution of the major allele for each SV site.}
    \label{fig:aim2_fig5}
\end{figure}

\subsection{Diverse, clustered SVs}
Our SV graph construction approach preserves multiple alleles cataloged at a given SV site and decomposes them into a parsimonious joint representation.
In general, these SV representations require more alleles per site than is common for small variants.
For example, there may be SNVs and indels within the sequence of an insertion or around a deletion’s breakpoints, or copy-number changes in variable number tandem repeat (VNTR) regions.
The existence of these potentially recombining subvariants implies the possibility of previously unidentified alleles.

We genotyped a total of about 1.7 million alleles clustered in 167,858 SV sites across the 2000 MESA samples.
In most SV sites, we only observed one or a few alleles ($\sim90\%$ of SV sites with five or fewer alleles; Figure \ref{fig:aim2_fig5} A).
Additionally, most of the SV sites ($\sim151,000, 90\%$) contained SV alleles that differed by only small variants (Section \ref{subsec:aim2:svclustering}), whereas the rest of the sites showed size variation from polymorphic VNTR regions (Figure \ref{fig:svsites_mesa}A).
Examples of SV sites that illustrate these different profiles are given in Figure \ref{fig:aim2_fig5} B and C, and Figure \ref{fig:mesa-svsite-examples}.
Figure \ref{fig:aim2_fig5}, D and E, shows the size and frequency distributions of the most common allele at each site.
SVs spanned the size spectrum (50 bp up to 125 kbp), with $89.8\%$ shorter than 500 bp.
For $84\%$ of the SVs, simple repeats or low-complexity regions overlapped at least $50\%$ of the SV region.
Hence, the SVs genotyped in this study match the original SVs discovered in long-read sequencing studies \cite{zook_robust_2020,chaisson_sv_2019,audano_hgsvc} in terms of number, size distribution, and sequence context.

We observed similar patterns in the 1000 Genomes Project dataset.
We identified 1.9 million alleles clustered in 167,188 SV sites, with a size and frequency distribution similar to that of the MESA cohort (Figure \ref{fig:sv-1kgp-stats}).
The 1000 Genomes Project dataset also provided 602 trios that we used to estimate the quality of our genotypes.
First, we computed the rate of Mendelian error, which was $5.2\%$ for deletions and $4.7\%$ for insertions when considering all variants.
This error decreased as the confidence in the genotype increased. For example, the Mendelian error dropped to 2.1 and $2.5\%$ for the $\sim70\%$ of deletions and insertions, respectively, with the highest genotype qualities (Figure \ref{fig:sv-trio-eval}).
The most common error by far occurred when a heterozygous variant was predicted in the offspring but both parents were predicted homozygous for the reference allele (Table \ref{tab:sv-mend-error}).
The transmission rate of heterozygous alleles was close to the expected $50\%$: 40 to $47\%$ for deletions and 43 to $49\%$ for insertions (Figure \ref{fig:sv-trio-eval}B).

\subsection{Comprehensive SV frequency estimates}
The genotyped SVs were originally discovered with long-read sequencing technology, and many are absent from the population scale SV catalogs that could provide frequency information.
Of the SV sites genotyped using our pangenome approach, $93\%$ are missing from the 1000 Genomes Project SV catalog \cite{1000gp_sv_2015}, and $67\%$ were missing from the Genome Aggregation Database (gnomAD)–SV catalog \cite{gnomadsv_2020} (Table \ref{tab:novel-sv}).
This is consistent with the amount of previously unidentified structural variation described in the three studies from which our SV graph is derived \cite{zook_robust_2020, chaisson_sv_2019,audano_hgsvc}.
Our results provide frequency estimates across a large and diverse cohort for these SVs.

The frequency distribution resembled the allele frequency distributions in the 1000 Genomes Project SV and gnomAD-SV catalogs (Figure \ref{fig:sv-freq-comp}A).
The frequencies of the subset of variants present in both our catalog and the mentioned public catalogs were largely concordant (Figure \ref{fig:sv-freq-comp}B-C).
Our frequency distribution looks rather different than that of SVPOP \cite{audano_hgsvc}.
However, we note that SVPOP’s frequency distribution is markedly different than the 1000 Genomes Project and gnomAD-SV (Figure \ref{fig:sv-freq-comp}A) and has very different frequency estimates on matched variants (Figure \ref{fig:sv-freq-comp}D,F).

\subsection{Fine-tuning SVs with frequencies}
SVs in the input catalogs may contain errors.
When multiple alleles co-occur at an SV site, we often observed that one allele was frequently present in the cohort, whereas other similar alleles were not (Figure \ref{fig:aim2_fig5} B and C).
The other alleles at these sites are either rare or erroneous.
In either case, it is useful to identify the major alleles.
In 7520 SV sites, only one allele was called in more than $1\%$ of the population, whereas other alleles from the original catalogs were not.
Further, the major allele was at least three times more frequent than the second most frequent allele in 6175 of these sites (Figure \ref{fig:svsites_mesa}B).
As a quality control, we verified that these alleles were more likely to match exactly with the alleles in the GIAB truth set \cite{zook_robust_2020}, which is the SV catalog with the highest base-level confidence [permutation p < 0.0001; Section \ref{subsec:aim2:svfinetuning}].
Our results thus help fine-tune the sequence resolution of these SVs.
More generally, our results identify one major allele for 39,699 multiallelic SV sites.

\subsection{SV frequency population signatures}
\label{subsec:aim2:inter-super-pop}
Principal components analysis (PCA) of the allele counts at the 166,959 SV sites in the MESA cohort produces a low-dimensional embedding of the samples.
This embedding appears similar to the TOPMed consortium’s PCA of SNV genotype data from all samples (Pearson correlation of 0.96 to 0.99 for the top three components; Figure \ref{fig:mesa-topmed-pcs}.
This result is expected and provides confirmatory support for the accuracy of our SV genotypes.

We clustered samples with PCA, taking each cluster to be a population (Section \ref{subsec:aim2:sv-pop-freq}).
Allele frequencies vary across these populations for thousands of SV sites (Figure \ref{fig:mesa-pop-freq}A-C).
For example, we found 21,069 SV sites with strong intercluster frequency patterns, defined by a frequency in any population differing by more than $10\%$ from the median frequency across all populations (Figure \ref{fig:mesa-pop-freq}D).
The existence of SVs with different frequencies across populations supports the need to develop and test genomic tools and references across multiple populations.

Because there is a risk of circularity when using the same genotype data to define populations and look for patterns across them, we replicated these observations in the high-coverage 1000 Genomes Project dataset \cite{1000gp_nygc_2021}.
Here, again, the PCA of the allele counts organized the samples in a way consistent with the known history of the 1000 Genomes Project “superpopulation” groups (Figure \ref{fig:1kgp-sv-pcs}).
In this analysis, we found 25,960 SV sites with strong inter-superpopulation frequency patterns, defined as for the MESA analysis, but with the 1000 Genomes superpopulations as the sample categories (Figure \ref{fig:1kgp-pop-freq}).
As a comparison, when the samples were randomly grouped into superpopulations, we observed only 14 SV sites with strong intergroup frequency patterns (Section \ref{subsec:aim2:sv-pop-freq}).
More than 17,000 SV sites with strong inter-superpopulation frequency patterns were enriched or depleted in the African Ancestry (AFR) superpopulation, followed by about 10,000 sites enriched or depleted in the East Asian Ancestry (EAS) superpopulation.

As an example of a newly annotated variant, a deletion of the RAMACL gene was genotyped with frequency $46.6\%$ in the AFR super population, $4\%$ in American Ancestry (AMR), and less than $1\%$ in other superpopulations.
This deletion is not present in the 1000 Genomes Project SV catalog and was unresolved in version two of the gnomAD-SV catalog.
It has been curated in gnomAD-SV v2.1 and shows similar population patterns there to what we found in our reanalysis of the 1000 Genomes Project dataset.
Such variants could be falsely identified as putatively pathogenic if analyzed only in European-ancestry populations where the frequency is low.

In addition, our approach is often capable of genotyping repeat-rich variants, such as short tandem repeats that vary in length.
For example, a 1-kbp expansion of an exonic VNTR in MUC6 with a frequency of $14\%$ in the AFR superpopulation was observed only rarely outside of it: $2.3\%$ in AMR and $<1\%$ in other superpopulations (Figure \ref{fig:aim2_fig6} A).
This repeat expansion is absent from gnomAD-SV and the SV catalog from the 1000 Genomes Project, despite its observed frequency.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{aim2_fig6.pdf}
    \caption[Population-specific SVs and SV-eQTLs in the 1000 Genomes Project dataset]{\textbf{Population-specific SVs and SV-eQTLs in the 1000 Genomes Project dataset.} (A) Example of an insertion at appreciable frequency ($\sim14\%$) in the AFR superpopulation that is rare ($<3\%$) in the other superpopulations. The variant is a 1011-bp expansion of a VNTR in the coding sequence of the MUC6 gene. chr11, chromosome 11; TRF, Tandem Repeats Finder. (B and C) Association between a 10,083-bp insertion overlapping a predicted enhancer and the gene expression of the PRR18 gene. Each allele is associated with an increase in gene expression, as shown in (B). The position of significant eQTLs (SNV-indels in green, insertions in blue) is shown in (C). All the eQTLs are in the intergenic region downstream of the PRR18 gene. The y axis represents the significance of the association, with the top eQTL being the highest point. Of note, the lead eQTL (the 10,083-bp insertion) overlaps a region predicted to be an enhancer by ENCODE. In (B), boxes represent the median and quartiles; whiskers extend from the box up to 1.5 times the interquartile range.}
    \label{fig:aim2_fig6}
\end{figure}

\subsection{SVs, genes, and expression}
In the MESA and 1000 Genomes Project datasets, 1563 and 1603 SVs overlapped coding regions of 408 and 380 protein-coding genes, respectively.
When including promoters, introns, and untranslated regions, each dataset had overlaps between at least 78,290 SVs and 7641 protein-coding genes.
Of these SVs, 10,640 show strong inter-superpopulation frequency patterns in the 1000 Genomes Project dataset (see Figure \ref{fig:aim2_fig6} A).

We searched for associations between SVs and gene expression across 445 samples from the 1000 Genomes Project that have been RNA sequenced by the Genetic European Variation in Disease (GEUVADIS) consortium \cite{geuvadis_2013}.
These samples span four European-ancestry populations [Utah residents (CEPH) with Northern and Western European ancestry (CEU), Finnish in Finland (FIN), British in England and Scotland (GBR), and Toscani in Italy (TSI)], and the Yoruba in Ibadan, Nigeria (YRI) population \cite{geuvadis_2013}.
A pooled analysis identified 2761 expression quantitative trait loci (eQTLs) across 1270 genes [false discovery rate of $1\%$; Section \ref{subsec:aim2:eqtldiscovery})].
Of those genes, 878 are protein-coding genes. We note that $58\%$ of the SV-eQTLs are located within simple repeats or low-complexity regions.
The distribution of the p values across all tests showed the expected patterns for genome-wide association studies (Figure \ref{fig:eqtl_qc}).

Genes with eQTLs, or eGenes, were enriched in gene families involved in immunity, as previously observed \cite{fagny_exploring_2017}, but we also found significant enrichments in other families (Table \ref{tab:file-sveqtl}).
For example, 3 of the 10 genes in the anoctamins family have SV-eQTLs (adjusted p = 0.0006).
This gene family is involved in the regulation of multiple processes, including neuronal cell excitability, and mutations in some of its members have been linked to neurologic disorders \cite{benarroch_2017}.
Other families enriched included the survival motor neuron (SMN) complex family (3 out of 10 genes with an SV-eQTL, adjusted p = 0.0012) and aldehyde dehydrogenases genes (3 out of 19 genes with an SV-eQTL, adjusted p = 0.008).
As expected, SV-eQTLs were strongly enriched in coding, intronic, promoter, untranslated, and regulatory regions (Figure \ref{fig:eqtl_enr}).
Interestingly, SVs associated with decreased gene expression drove most of the enrichment in coding regions.
Separate analysis of the four European-ancestry populations together and the YRI population alone identified, respectively, 44 and 139 SVs where an association with the expression of protein-coding genes was detected only in the smaller analysis (Section \ref{subsec:aim2:eqtldiscovery}).
As expected, a number of these population-specific SV-eQTLs had shown strong inter-superpopulation frequency patterns (see above).

Finally, we performed a joint analysis with available SNV and indel calls. 
Like previous studies \cite{gtex_sv_2017,Ebert2021}, we found that the lead eQTLs (the strongest association for a gene) are enriched in SVs (permutation p = 0.022).
For example, only $0.5\%$ of the variants tested were SVs, but SVs were the lead eQTL in $5.9\%$ of the genes that had both SV and SNV-indel eQTLs.
We did not observe a difference in relative effect size of SV-eQTLs compared with SNV-indel eQTLs, but we noticed that SV-eQTLs were fourfold enriched in the genes with the highest expression (permutation p = 0.004; Figure \ref{fig:eqtl_enr_ge}).
Figure \ref{fig:aim2_fig6}, B and C, and Figure \ref{fig:eqtl_ex} show two examples where the SV-eQTL is the strongest association: a 10,083-bp insertion associated with an increased expression of the PRR18 gene and a 5405-bp deletion associated with a reduced expression of the SLC44A5 gene.
In addition, 39 genes had SV-eQTLs but no SNV-indel eQTLs (Table \ref{tab:file-sveqtl}).
These results show that the SV genotypes produced here can be used to test for phenotypic association.

\section{Discussion}
Pangenome references hold great potential as a replacement for standard linear reference genomes.
They can represent diverse collections of human genomes, and they have been shown to reduce the bias that arises from using a linear reference \cite{garrison_variation_2018}.
However, because of the appreciable complexity of the task, previous methods for mapping to pangenomes have been slow or not clearly better than comparable methods for linear genomes.
By contrast, Giraffe can map to pangenome graphs consisting of thousands of aligned haplotypes, potentially with complex topologies, with accuracy comparable to that of the best previously published tools and speed surpassing linear reference mappers.
Further, we have demonstrated that its mappings can improve genotyping.

Pangenome exchange formats have been coevolving alongside pangenome methods.
Giraffe is designed to meet and solidify these emerging standards while also interfacing with the broader genomics ecosystem.
The graphical fragment assembly (GFA) format for representing pangenome graphs has increasing tool support, including by vg \cite{rautiainen_graphaligner_2020,li_minigraph_2020,koren_canu_2017,li_minimap_2016,wick_bandage_2015,spades_2020}.
In addition, Giraffe can output the graphical mapping format (GAF) read-to–pangenome graph alignment format proposed by Li et al. \cite{li_minigraph_2020} and supported by other pangenome mappers \cite{rautiainen_graphaligner_2020}.
Giraffe also supports backward compatibility to linear references by allowing mappings to be projected onto an embedded linear reference genome and output in standard formats.
The state-of-the-art SNV and short-indel genotyping results described in this study demonstrate the value of this support.
These necessary technical advances are starting to nucleate an interoperable tool ecosystem for pangenomics.

For SVs, and for particularly large insertions, we and others have shown that the benefits of pangenomes for genotyping are not merely incremental but transformative \cite{hickey_vgsv_2020,li_minigraph_2020,chen_paragraph_2019}.
Our approach allowed us to identify duplicate SVs, to refine the canonical definitions of SVs, and to establish the frequencies of these SVs in diverse human populations.
Complementing previous surveys of SVs in diverse human populations \cite{1000gp_sv_2015,Ebert2021,sudmant2015svdiversity}, we demonstrate that many of the previously unidentified SVs studied here are also differentially distributed across human populations.
This frequency information could be used, among other applications, for prioritizing variants to investigate for genomic medicine because variants common anywhere are unlikely to be pathogenic.

We expect accurate and unbiased SV genotyping to be one of the most impactful contributions of pangenomics.
Among other applications, this contribution will enable more links from SVs to disease traits and other phenotypes to be identified.
For example, we were able to detect thousands of associations between SVs and gene expression.
Ebert et al. \cite{Ebert2021} recently performed a similar analysis using the same RNA sequencing (RNA-seq) dataset from the GEUVADIS consortium (complemented with 34 new deep RNA-seq experiments) and genotypes for SVs discovered in 32 haplotype-resolved genomes.
Although we did not use this new sequencing data and SV catalog, we found a similar number of SV-eQTLs with our pangenomic approach [2761 SV-eQTLs and 1270 eGenes in this study; 2109 SV-eQTLs and 1526 eGenes in Ebert et al. \cite{Ebert2021}].

Soon, pangenomes will be built from larger collections of high-quality de novo assembled genomes using accurate long reads.
We hope such human pangenomes will enable more comprehensive genotyping of common complex variants (including SVs) from existing catalogs of short-read sequencing data, allowing for the typing of such variants at the scale of existing catalogs of point variation.
We expect that unlocking this latent information will ultimately aid with disease association studies and help us further understand how the architecture of the genome contributes to an individual’s phenotype.

\section{Methods summary}

\subsection{Evaluation}
\subsubsection{Read simulation}
To evaluate Giraffe for mapping human data, we obtained paired-end sequencing reads from a parent-child pedigree.
Reads were obtained from an Illumina NovaSeq 6000 machine for parent NA19239 (accession ERR3239454) and from Illumina HiSeq 2500 and HiSeq X Ten machines for child NA19240 (accession nos. ERR309934 and SRR6691663, respectively).
These samples were selected because NA19240 has genotypes for the HGSVC variants \cite{chaisson_sv_2019}, whereas NA19239 has genotypes for the 1000GP variants \cite{1000gp_2015}.
NA19239 was excluded from the 1000GP graph (Section \ref{subsec:aim2:graphconstruction}).
We simulated 1 million read pairs (2 million reads) from each individual’s haplotypes (Section \ref{subsec:aim2:readsim}).

\subsubsection{Read mapping accuracy}
Simulated read sets were mapped to the graphs using Giraffe, VG-MAP \cite{garrison_variation_2018}, HISAT2 \cite{kim_hisat2_2019}, and GraphAligner \cite{rautiainen_graphaligner_2020}.
We were unable to build a HISAT2 index for the full 1000GP graph, and so instead we mapped it to a graph created from a subset of the 1000GP data where all variants with a frequency below 0.001 were filtered out.
In addition, we mapped the read sets to the primary graphs using Giraffe and to the linear reference assemblies using the linear sequence mappers BWA-MEM \cite{li_bwa_mem_2013}, Bowtie2 \cite{langmead_bowtie2_2012}, and Minimap2 \cite{li_minimap2_2018}.
Mapping accuracy was evaluated by comparing the positions along embedded, shared linear paths at which reads fell after mapping with similarly determined positions for their original simulated alignments.

\subsubsection{Read mapping speed}
We compared mapping runtime, speed, and memory usage on an AWS EC2 i3.8xlarge node with 32 vCPUs and 244 GB of memory.
To estimate real-world runtime and memory usage, we aligned a shuffled read set of 600 million NovaSeq 6000 reads from NA19239.
We mapped reads to the 1000GP graph, the HGSVC graph, and the GRCh38 linear reference for comparison and measured runtime and memory usage.
For each tool, we also separately measured reads mapped per thread per second, ignoring the start-up time of the mapper (Fig.\ref*{fig:aim2_supplement_speed}).
This measure gives an estimate of speed that is invariant to read-set size or thread count, except for the effects of long-running work batches and thread synchronization overhead (Section \ref{subsec:aim2:srgiraffe_speed}).

\subsubsection{Read-mapping bias}
To assess reference allele mapping bias, we mapped 600 million real paired-end NovaSeq 6000 reads for NA19239 to the 1000GP graph using default Giraffe and VG-MAP.
For comparison, we mapped the same reads to GRCh38 with BWA-MEM.

\subsubsection{Genotyping accuracy}
\label{subsec:aim2:genotyping-accuracy-methods}
We compared the performance of Giraffe, VG-MAP, Illumina’s Dragen platform, and BWA-MEM for genotyping SNVs and short indels.
The design of each calling pipeline is described in section \ref{subsec:aim2:dragen} and the parameters and indexes for each experiment are described in Table \ref{tab:vgruns_grch38}.
The variants produced by each pipeline were compared against the GIAB v4.2.1 HG002 high-confidence variant-calling benchmark \cite{wagner_benchmarking_2020} using the RealTimeGenomics vcfeval tool \cite{cleary2015comparing} and Illumina’s hap.py tool \cite{happy_2020}.
This benchmark set covers $92.2\%$ of the GRCh38 sequence.

We also evaluated a DeepVariant \cite{poplin_universal_2018} pipeline that uses Giraffe mappings (Section \ref{subsec:aim2:deepvariant_calling}).
Using the default DeepVariant 1.1.0–trained model, we tested genotyping of the HG003 sample across the entire genome.
This sample was not used in training the model.

\subsubsection{Generalization to yeast}
\label{subsec:aim2:yeast-methods}
To evaluate Giraffe’s performance on more diverged, nonhuman data, we used a yeast graph built from a Cactus multiple sequence alignment for five strains of the S. cerevisiae and S. paradoxus yeasts \cite{hickey_vgsv_2020}.
For the corresponding negative-control primary graph, we used the S.c. S288C assembly.
We collected basic statistics about the yeast graph and decomposed the graph for analysis using the method of \cite{paten_superbubbles_2018}.
We simulated 500,000 read pairs from a held-out S. cerevisiae yeast strain, DBVPG6044, not included in the yeast graph, using an error and length model for Illumina HiSeq 2500 reads (Section \ref{subsec:aim2:readsim}).

\subsubsection{SV genotyping}
We built an SV pangenome from the HGSVC \cite{chaisson_sv_2019}, GIAB \cite{zook_robust_2020}, and SVPOP \cite{audano_hgsvc} sequence-resolved catalogs.
After filtering out erroneous duplicates using a remapping approach, the SVs were iteratively inserted in the genome graph to minimize the effect of errors and redundancy in the catalog.
The SVs were then genotyped across 5202 genomes by aligning short-read sequencing data using Giraffe with a workflow description language (WDL) workflow that we deposited in Dockstore \cite{vgsv_dockstore}.
Two-thousand samples were selected from the MESA cohort to maximize sample diversity.
The remaining 3202 samples are from the 1000 Genomes Project and include 2504 unrelated individuals. The trios available in this latter dataset were used to compute the rate of Mendelian concordance in the genotypes.

The different SV alleles observed in the population were clustered into SV sites based on their reciprocal overlap (for deletions) and sequence similarity (for insertions).
We used the frequency profile across alleles within an SV site to identify the major allele and to fine-tune variants with near duplicates in the combined catalog that may have been due to errors.
Each variant was then annotated with its presence in existing SV databases \cite{audano_hgsvc,1000gp_sv_2015,gnomadsv_2020}, its repeat content, and its location relative to gene annotations.
We also compared the frequency distributions across the SV databases and how well the frequency estimates matched for variants shared across databases.

PCA was performed on the SV genotypes, and principal components were compared with those produced from SNV-indel genotypes.
We defined strong intercluster or inter-superpopulation frequency patterns by a frequency in any cluster or superpopulation differing by more than $10\%$ from the median frequency across all of them.
For the 2000 MESA samples, the clusters were defined using hierarchical clustering on the first three principal components.
For the 1000 Genomes Project, we used their “superpopulation” assignments.
Permutations were used to contrast the number of SVs with such patterns with an expected baseline.

Finally, we examined the SV genotypes in a subset of the samples that had gene-expression data available from the GEUVADIS consortium \cite{geuvadis_2013}.
MatrixEQTL \cite{matrix_eqtl_2012} identified SV-eQTLs while controlling for sex and population structures, as summarized by the first four principal components.
Separate analyses of the four European-ancestry populations together and the YRI population alone were performed similarly.
In addition, we performed a joint eQTL analysis with publicly available SNVs and indels \cite{1000gp_nygc_2021}.
We used permutation to compute enrichment of SV-eQTLs in gene regions, gene families, or among lead-eQTLs (those with the strongest association for a gene).

\section{Acknowledgments}
We acknowledge the studies and participants who provided biological samples and data for the TOPMed project.
The views expressed in this manuscript are those of the authors and do not necessarily represent the views of the National Heart, Lung, and Blood Institute (NHLBI); the National Institutes of Health (NIH); or the US Department of Health and Human Services.
\subsection{Funding}
Research reported in this publication was supported by the NIH under award numbers U41HG010972, R01HG010485, U01HG010961, OT3HL142481, OT2OD026682, U01HL137183, and 2U41HG007234.
Research reported in this publication was supported by the NHLBI BioData Catalyst Fellows Program of the NIH through the University of North Carolina at Chapel Hill, under award number OT3HL147154. J.A.S. was supported by the Carlsberg Foundation.
Computational resources for the project were made available by the NIH and by Amazon Web Services, without full compensation at market value.
The high-coverage sequencing data for the 1000 Genomes Project were generated at the New York Genome Center with funds provided by National Human Genome Research Institute (NHGRI) grant 3UM1HG008901-03S1 and can be found on Terra.
MESA and the MESA SHARe projects are conducted and supported by the NHLBI in collaboration with MESA investigators.
Support for MESA is provided by contracts 75N92020D00001, HHSN268201500003I, N01-HC-95159, 75N92020D00005, N01-HC-95160, 75N92020D00002, N01-HC-95161, 75N92020D00003, N01-HC-95162, 75N92020D00006, N01-HC-95163, 75N92020D00004, N01-HC-95164, 75N92020D00007, N01-HC-95165, N01-HC-95166, N01-HC-95167, N01-HC-95168, N01-HC-95169, UL1-TR-000040, UL1-TR-001079, and UL1-TR-001420.
Funding for SHARe genotyping was provided by NHLBI contract N02-HL-64278.
Genotyping was performed at Affymetrix (Santa Clara, CA, USA) and the Broad Institute of Harvard and MIT (Boston, MA, USA) using the Affymetrix Genome-Wide Human SNP Array 6.0.
This work was also supported in part by the National Center for Advancing Translational Sciences, CTSI grant UL1TR001881, and the National Institute of Diabetes and Digestive and Kidney Disease Diabetes Research Center (DRC) grant DK063491 to the Southern California Diabetes Endocrinology Research Center.
Whole-genome sequencing (WGS) for the TOPMed program was supported by the NHLBI.
WGS for “NHLBI TOPMed: Multi-Ethnic Study of Atherosclerosis (MESA)” (phs001416) was performed at the Broad Institute of MIT and Harvard (3U54HG003067-13S1 and HHSN268201500014C).
Core support, including centralized genomic read mapping and genotype calling, along with variant quality metrics and filtering were provided by the TOPMed Informatics Research Center (3R01HL-117626-02S1; contract HHSN268201800002I).
Core support, including phenotype harmonization, data management, sample-identity quality control, and general program coordination, was provided by the TOPMed Data Coordinating Center (R01HL-120393; U01HL-120393; contract HHSN268201800001I).

\subsection{Author contributions}
Project design: D.H., E.G., B.P. Giraffe implementation: J.S., X.C., A.M.N., J.M.E., B.P. SV analysis: J.M., G.H. Short-variant analysis: C.M., P.-C.C., A.C. The vg implementation: J.S., J.M., X.C., A.M.N., J.M.E., C.M., J.A.S., G.H., D.H., E.G., B.P. Manuscript writing: J.S., J.M., X.C., A.M.N., J.M.E., C.M., J.A.S., G.H., B.P. Data production: N.G., S.G., T.W.B., A.R., K.D.T., S.S.R., J.I.R.

\subsection{Competing interests}
 P.-C.C. and A.C. are employees of Google and own Alphabet stock as part of the standard compensation package. The remaining authors declare no competing interests.

subsection{Data and materials availability}
\label{sec:aim2:code-data}
An overview of the data generated for this paper, and key input data to reproduce the analyses, is available at https://cglgenomics.ucsc.edu/giraffe-data/.
The dataset is available through InterPlanetary File System (IPFS) at https://ipfs.io/ipfs/QmVo4Q5hCKqUGJJZyYLGJTaiHZdK9JWhJtGJbKa9ojrSjh.
Archived copies of the code and final reusable work products have been deposited at Zenodo \cite{zenodocode}.
This archive also includes vg, toil-vg, and toil source code and Docker containers used in this work, as well as the giraffe-sv-paper orchestration scripts.
“Final” versions of vg and toil-vg, including all features needed to reproduce this work, are 9907ab2 for vg and 99101f2 for toil-vg.
The latest version of the vg toolkit, including the Giraffe mapper, is customarily distributed at https://github.com/vgteam/vg.
The scripts used for the analysis presented in this study were developed at https://github.com/vgteam/giraffe-sv-paper, a git bundle of which is archived at Zenodo \cite{zenodocode}.
Data used in the Giraffe read-mapping experiments—including the 1000GP, HGSVC, and yeast target graphs, the linear control graphs, the graphs used to simulate reads, and the simulated reads themselves—can be found at https://cgl.gi.ucsc.edu/data/giraffe/mapping/.
The SV pangenomes and SV catalogs annotated with allele frequencies are hosted at 
https://cgl.gi.ucsc.edu/data/giraffe/calling/ and archived at Zenodo \cite{zenodocode}.
This repository also includes SVs with strong inter-superpopulation frequency patterns, SV-eQTLs, and SVs that overlap protein-coding genes.
To build the 1000GP and HGSVC graphs, we used the GRCh38 no-alt analysis set (accession no. GCA\_000001405.15) and the hs38d1 decoy sequences (accession no. GCA\_000786075.2), both available from the National Center for Biotechnology Information (NCBI), in addition to the variant call files distributed by the respective projects. To train read simulation and evaluate speed, we used human read sets ERR3239454, ERR309934, and SRR6691663 and yeast read sets SRR4074256, SRR4074257, SRR4074394, SRR4074384, SRR4074413, SRR4074358, and SRR4074383, all available from Sequence Read Archive (SRA).
The public high-coverage sequencing dataset from the 1000 Genomes Project \cite{1000gp_nygc_2021} is available at www.internationalgenome.org/data-portal/data-collection/30x-grch38, including European Nucleotide Archive (ENA) projects PRJEB31736 and PRJEB36890.
The gene-expression data were download from ArrayExpress E-GEUV-1 (GD462.GeneQuantRPKM.50FN.samplename.resk10.txt.gz).
We downloaded the call sets from the ENCODE portal \cite{sloan_encode_2016} (www.encodeproject.org/) with the identifier ENCFF590IMH.
Individual WGS data for TOPMed whole genomes are available through dbGaP.
The dbGaP accession no. for MESA is phs001416.
Data in dbGaP can be downloaded by controlled access with an approved application submitted through their website: www.ncbi.nlm.nih.gov/gap.

\chapter{Long read mapping}
\label{chapter:lr-giraffe}
\section{Preface}

\chapter{Discussion}

We are in an era of tremendous growth in the field of genomics.
Recent advances in sequencing technologies and bioinformatics tools have made sequencing experiments faster, cheaper, and more accurate, leading to a proliferation of high-quality human genome sequences being generated.
This abundance of data has granted us greater insight into human genetic variation and its distribution in the human population.
But as we learn more about human genetic diversity, there is a growing recognition that standard practices are insufficient for accurately and equitably detecting and interpreting genetic variants. 
Pangenomes are a promising alternative to standard linear genomes that can better represent the genetic landscape of a species and reduce bias in analyses.
With the recent progress in sequencing and population genomics, it is now possible to generate reference-quality genome assemblies at the scale necessary for creating a representative human reference pangenome.

The first human reference pangenomes are just beginning to be produced and released to the public for general use.
However, due to their novelty and the technical challenges of working with a larger and more complex data structure, methods for working with pangenomes are less mature than analogous methods for linear genomes.
In this dissertation, I presented tools for indexing pangenome graphs and for mapping long and short sequencing reads to them.
These mappers are among the first practical tools capable of mapping to pangenome graphs at large scales, a crucial step for many genomics pipelines.

Although we have shown Giraffe to be efficient for the first draft of the HPRC graphs, there is still work to be done to ensure that it works with increasingly complicated graphs.
The distance index has become a major barrier for mapping to topologically complex graphs due to the quadratic complexity of its representation of distances in snarl netgraphs.
In order for Giraffe to function on graphs with more haplotypes, graphs representing species with more genetic divergence, or graphs that allow more collapsing of similar sequences, the distance index must be changed to more efficiently represent distances within snarls.

This has been an area of recent exploration in the lab.
One potential solution that I discussed with Simon Heumos is to use his layout algorithm from odgi to estimate a low-dimensional embedding of the netgraph.
Odgi layout uses stochastic gradient descent to find the optimal set of 2-dimensional coordinates for each node such that the distance between all pairs of nodes in the coordinate plane best matches the distances between the nodes on embedded paths in the graph \cite{guarracino_odgi_2022}.
An index like this would use $O(ND)$ space, where $N$ is the number of nodes and $D$ is the number of dimensions, but such an approach would allow distances between all pairs of nodes, even though most pairs of node sides are unreachable in a net graph.
The embedding could be paired with a bit-vector representing reachability between nodes, but even a bit vector with quadratic cost may be too big for the largest snarls. 
Zia Truong, a rotation student whom I co-mentored with Adam Novak, explored using landmark-based distances for netgraphs.
Her algorithm finds a set of landmark nodes that are expected to be included in most paths through the snarl, then stores the distance from each node to each landmark.
Distances between nodes can be estimated by finding the distance from each node to a common landmark.
The memory cost of the index is $O(NL)$ where $L$ is the number of landmarks, and the runtime for calculating distance is $O(L)$.
Another project led by Jouni Sirén has been to estimate distances using the haplotype sequences in the graph.
A haplotype-based distance has the advantage that it uses distances from real sequences, rather than using the graph topology which may produce biologically unrealistic distances.

Efficiently indexing a graph is one of many problems that arise as pangenomes grow in size and complexity; analyses also tend to become slower and at times less accurate as the reference pangenome grows \cite{Pritt2018}.
Pangenomes cannot grow indefinitely and no single pangenome will be able to represent all variants of interest for every study.
However, a pangenome graph could be used as a more versatile reference that can be modified for specific applications.
The recent personalized pangenomes paper demonstrates how variants can be removed from a pangenome to better represent an individual sample \cite{siren_personalized_2024}. 
Conversely, variants specific to a population, disease, or individual could be added to a reference pangenome.
%TODO: Include the Emblask-weaver pipeline if it is published
Adding variants to a graph is more difficult than removing them because the graph must be re-indexed in order to map to it.
While any modification to the graph will change the indexes, re-indexing a reduced graph may not be necessary if the new index will be a subset of the old and, as in the case of the personalized pangenome workflow, the new graph may be small enough for indexing to be very fast.
Re-indexing a graph with additional variants, particularly larger variants connecting disparate regions of the genome, is a more difficult task. 

I propose a strategy for adding a small number of chromosomal rearrangements to a pangenome as a target for read mapping using the long read Giraffe algorithm.
Rather than changing the graph itself and re-indexing, the additional variants would only be considered during mapping.
The variants would be represented in the zip code tree as edges that connect disparate chains in the zip code tree with no distance.
Although the zip code tree structure is based on the snarl decomposition, it is not necessary for the snarl decomposition represented in the zip code tree to be valid in order to find distances using traversals of the zip code tree, and the zip code tree will still be valid after adding these extra edges.
Chaining can be done as usual using the extra edges to consider mappings that span chromosomal rearrangements and alignment can be done on the chain on each side of the rearrangement edge separately.

An approach like this could be used for mapping reads derived from cancer tumors containing translocations.
Long reads aligned to a pangenome with split-read mapping enabled could be used to identify putative chromosomal rearrangements.
Using these rearrangements as added edges in the proposed algorithm, shorter reads could be mapped to the graph considering the putative rearrangements. 



\appendix
\chapter{Additional short read giraffe materials}
\label{sec:appendix_sr_giraffe}
\section{Preface}
This section contains materials from the supplement of short read giraffe paper \cite{sr_giraffe_2021}. 

\section{Supplementary methods}

\subsection{Genotyping and evaluating short variants with Dragen}
\label{subsec:aim2:dragen}

We mapped $\sim$830~million~paired-end, 150-bp-long reads (Precision FDA Challenge V2 Illumina $\sim$35x~coverage) from the HG002 sample to the 1000GP graph.
We also separately evaluated mapping $\sim$1.08 billion 250-bp-long reads ($\sim$40-50x~coverage of Illumina HiSeq~2500) from HG002 to see if using longer reads and higher coverage would affect the results.
For the genome graph mappers, we evaluated variant calling performance by using \texttt{vg~surject} to produce BAM representations of our graph alignments projected onto the linear reference assembly, and then using Dragen version~3.7.5 to call variants against the \texttt{hs38d1} reference for each set of alignments.
Dragen was used as the primary variant caller because Illumina, who sells it, has found it to produce robust results\cite{illumina_dragen_2019,illumina_dragen_pfda_2017,illumina_dragen_pfda_2020}.
Its speed was also useful for the purposes of rapid evaluation of whole genome alignments of real read data.
No training or calibration was performed for any of the generated mappings other than those performed by default by Dragen itself.

All pipelines evaluated for short variant calling performance had the same structure.
First, we mapped reads to the appropriate GRCh38-based linear or graph reference using the pipeline's mapper.
Then, we genotyped the resulting alignments using Illumina’s ``Dragen Bio-IT Platform'' product, version~3.7.5, against an index generated from the \texttt{hs38d1} human genome reference.
The mappers for each pipeline evaluated were Illumina’s Dragen internal aligner, BWA-MEM, VG-MAP, Giraffe, and Giraffe in fast mode.
The Genome In a Bottle HG002 version 4.2.1 high-confidence VCFs were used as the truth sets for evaluating performance of variant calling\cite{chin2020diploid}.
The VCF was obtained from \url{https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/GRCh38/HG002_GRCh38_1_22_v4.2.1_benchmark.vcf.gz} and the high confidence regions evaluated were based on the BED files obtained from \url{https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/AshkenazimTrio/HG002_NA24385_son/NISTv4.2.1/GRCh38/HG002_GRCh38_1_22_v4.2.1_benchmark_noinconsistent.bed}.
We used RTG's \texttt{vcfeval} \cite{cleary2015comparing} and Illuminas \texttt{hap.py} \url{https://github.com/Illumina/hap.py} to evaluate variant calling concordance with truth sets.
All pipelines used the computational resources of the NIH HPC Biowulf cluster (\url{http://hpc.nih.gov}).



\subsubsection{Graph construction} \label{subsec:aim2:graph_construction}
For the variant calling experiments, graph references, and their indexes for running vg mappers, were constructed using different versions of vg ranging from \texttt{1.20.0} to \texttt{1.31.0}, orchestrated by \texttt{toil-vg~construct}.

The graph references for GRCh38-based experiments were constructed using vg version \texttt{v1.31.0} as packaged in container \texttt{quay.io/vgteam/vg:v1.31.0}, using the cannonical \texttt{hs38d1} FASTA reference file as sourced from \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/linear_references/GCA_000001405.15_GRCh38_no_alt_analysis_set_plus_GCA_000786075.2_hs38d1_genomic.fna} and the 1000 Genomes Project Phase 3 phased VCFs that were lifted over from old GRCh37-based joint-called datasets as sourced from \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000gp_data/ALL.chr*_GRCh38.genotypes.20170504.rename.vcf.gz}.
\vocab{Primary} graphs and indexes were constructed using just the linear reference FASTA with vg version \texttt{v1.26.0-180-gdc119fa04} as packaged in container \texttt{quay.io/vgteam/vg:ci-2284-dc119fa046aa7131a1a8e026be36da2d79bc2f22}.
\vocab{1000GP} graphs and indexes were constructing using both the FASTA and the VCFs after filtering out variants belonging to segmental duplication regions of greater than 10 kilobases in length as defined in the bed file \url{https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/genome-stratifications/v2.0/GRCh38/SegmentalDuplications/GRCh38_segdups_gt10kb.bed.gz} with vg version \texttt{v1.31.0} as packaged in container \texttt{quay.io/vgteam/vg:ci-2890-655a9622c3d60e87f14b88d943fbd8554214a975}.


\subsubsection{Read sets}
Two different read sets were used to evaluate performance
One was the 150~bp paired-end FASTQ set from sample HG002 as obtained from the FDA Precision Challenge dataset.
These reads are available as paired FASTQs at \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/test_input_reads/HG002.NovaSeq.pcr-free.35x.R1.fastq.gz} and \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/test_input_reads/HG002.NovaSeq.pcr-free.35x.R2.fastq.gz}.
The other read set consisted of 250~bp paired-end FASTQ reads from sample HG002, obtained from the GIAB NovoAligned BAM at \url{ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/HG002_NA24385_son/NIST_Illumina_2x250~bps/novoalign_bams/HG002.hs37d5.2x250.bam}.
These reads in paired FASTQ format are available at \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/test_input_reads/HG002_read_pair_1.fq.gz} and \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/test_input_reads/HG002_read_pair_2.fq.gz}.

\subsubsection{Read mapping}
The HISAT2 mapping runs were done using version~\texttt{2.1.0}.
Only default settings, with the addition of the \texttt{-{}-no-spliced-alignment} flag, were used during HISAT2 execution.

One pipeline used Illumina's Dragen module for both mapping and alignment; both steps were run against the same index derived from the \texttt{hs38d1} human genome reference.

The BWA-MEM mapping runs were done using version~\texttt{0.7.17-r1188} against the \texttt{hs38d1} human genome reference.

The vg alignment runs used different graph indexes depending on the mapper used (VG-MAP or Giraffe).
GRCh38-based experiment run details are given in Supplementary Table~\ref{tab:vgruns_grch38}.
All runs used the \texttt{toil-vg~map} workflow for the alignment procedure and ABRA2\cite{mose2019improved} for indel realignment after alignment.
GATK's Picard tool~\cite{Picard2019toolkit} was used to reorder aligned BAM files for contig consistency which is required by the Dragen variant calling algorithm.


\subsubsection{DeepVariant calling}
\label{subsec:aim2:deepvariant_calling}

All pipelines for the DeepVariant experiment evaluation used BWA-MEM version~\texttt{0.7.17-r1188} against the \texttt{hs38d1} human genome reference or VG Giraffe against the same 1000GP graph as described in \ref{subsec:aim2:graph_construction}.
Alignments were then indel realigned using ABRA2\cite{mose2019improved}.
The DeepVariant v1.1.0 code base was used for all experiments.

DeepVariant learns to call variants by training on input data from gold standard samples HG001-HG007.
In all DeepVariant models, the HG003 sample is fully withheld from training, allowing a full genome sample to be evaluated.
Because the DeepVariant production models for Illumina are trained on samples mapped with BWA, DeepVariant likely optimizes for the mapping accuracy and quality profile of BWA.
We used DeepVariant v1.1.0 production model for the BWA-MEM experiments and a custom model for the GIRAFFE alignments that were trained using the same methods that were used to train the DeepVariant model for BWA-MEM alignments.
The custom model data can be found here \url{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/deepvariant_models/model.ckpt-25600*}.

\subsection{Genotyping and evaluating structural variants}
\label{subsec:aim2:svgenotyping}

We replicated the evaluation performed in Hickey et al.\cite{hickey_vgsv_2020} using two SV graphs made from the HGSVC\cite{chaisson_sv_2019} and GIAB v0.6\cite{zook_robust_2020} SV catalogs, respectively.
The graphs had originally been built from VCF files provided by the HGSVC and GIAB consortia.
To evaluate Giraffe, we built the necessary indexes.
For the minimizer index, we used the default minimizer length of 29 and window size of 11.
The GBWT index was created using the greedy path-cover algorithm and $n = 32$ paths.
We then mapped and genotyped the SVs in four samples: HG00514, HG00733 and NA19240 for the HGSVC graph; HG002 for the GIAB graph.
The genotyped were compared to the truth-set using \texttt{sveval}\cite{hickey_vgsv_2020}.
We use non-repeat regions, i.e. regions of the genome that don't overlap simple-repeats and segmental duplications, as high-confidence regions for the HGSVC graph and the combined SV graphs that are both on GRCh38.
For the GIAB graph, which uses GRCh37, we use the high-confidence regions provided by the GIAB consortium\cite{zook_robust_2020}.
The scripts to build the pangenomes, genotype the SVs and evaluate the genotyping performance are available in the repository (see Section{sec:aim2:code-data}).

(see section \ref{sec:aim2:code-data}).

\subsection{Combining long-read catalogs for an SV pangenome}
\label{subsec:svpangenome}

We combined variants from the three SV catalogs used previously in Hickey et al.\cite{hickey_vgsv_2020}: HGSVC \cite{chaisson_sv_2019}, GIAB\cite{zook_robust_2020}, and SVPOP \cite{audano_hgsvc}.
The three catalogs were first normalized and merging using bcftools version 1.9 \cite{li_samtools_2011}.


To minimize issues with near-duplicate variants, we first mapped short reads from 17 diverse samples to a local graph containing all versions of a variant, and kept one version if substantially supported by the reads.
Near-duplicate variants often exists because they contain errors around their breakpoints.
Our aim was to filter out the most obvious errors before starting to build the SV graph.
We identified near-duplicates by overlapping the SVs in this combined catalog.
At this stage, we defined near-duplicate SVs as deletions with a reciprocal overlap at least 80\% or insertions located at less than 50 bp from each other and sizes at least 80\% reciprocally similar.
A network was build from this ``near-duplicate'' relationships to identify connected components of near-duplicate variants, which we referred to as SV clusters.
We identified 34,010 such clusters of near-duplicates SVs, each with on average 2.6 SVs.
For each SV cluster, we extracted the reference sequence and variants to create a local SV graph of the region.
We then aligned short-reads pooled from 17~diverse individuals selected to span different populations in the 1000 Genomes Project and HGSVC.
The reads aligning to the region of interest were extracted using SAMtools\cite{li_samtools_2011} from the aligned reads publicly available.
A subset of SV clusters didn't have SV-supporting reads, because they originally couldn't be mapped to the linear reference, were too difficult to map in general, or the variants were rare enough that none of the 17 individuals carried them.
Out of the 23,929 clusters with read support, 43.1\% had one variant supported by more than 50\% of the SV-supporting reads.
When reads supported one variant better than the other near-duplicates in the SV cluster, the near-duplicates were discarded.
This filtering step removed 55,330~near-duplicate SVs.


Although many obvious duplicates had been removed, many SVs sharing sequence remained.
For example if SVs were not covered by the short-reads used above or if they were too different to match the near-duplicate definition used above.
Instead of building a pangenome naively from the variant definition, we used a hybrid approach using iterative graph augmentation.
The goal is to collapse as much as possible variants that share sequence content by iteratively aligning and adding variants into the SV graph.
The graph was built in chunks separated by at least 10~kbp without any variants.
We focused on SVs shorter than 1~kbp which represented the vast majority of the near-duplicate variants and allowed us to parallelize this iterative graph augmentation approach.
For each chunk, we clustered SVs using a less stringent criterion as above: deletions with at least 30\% reciprocal overlap; insertion located at less than 100bp from each other and with at least 30\% reciprocally similar sizes.
The 18,286 clusters of SVs identified contained an average of 3.24 SVs.
A graph was built for the chunk using one variant per SV cluster.
One by one, the other variants were then added by aligning them to the graph and augmenting the graph.
We used \texttt{vg~mpmap} \cite{sibbesen2021haplotype} to align large sequences representing the SV variation flanked by 5~kbp of sequence context.
The alignment was added to the graph using \texttt{vg~augment}.
The chunked graphs was merged using \texttt{vg~concat}.

Finally, we added unplaced and unlocated contigs from the GRCh38 reference assembly to the pangenome.
We also added the \texttt{hs38d1} decoy sequences (accession GCA\_000786075.2).

The scripts used to build this pangenomes are documented in the repository (see Section \ref{sec:aim2:code-data}).

\subsection{Population scale analysis of SVs}

\subsubsection{Whole-genome sequencing datasets}

The MESA whole-genome sequencing dataset was obtained from NHLBI’s TOPMed program (\url{www.nhlbiwgs.org}), freeze 5b.
Paired-end 150bp reads had been sequenced on Illumina HiSeq X Ten instruments and achieved a mean depth of at least 30x.
All sequencing had used PCR-free library preparation kits.

For the 1000 Genomes Project samples, we used public whole-genome sequencing data generated at the New York Genome Center\cite{1000gp_nygc_2021} (see Section \ref{sec:aim2:code-data}).
Samples had been sequenced to a minimum of 30x mean genome coverage using PCR-free sequencing libraries on the Illumina NovaSeq 6000 sequencing instrument, with 150bp paired-end reads.
All cell lines had been obtained from the Coriell Institute for Medical Research and had been consented for full public release of genomic data.

Of note, the reads were downsampled to 20x in both datasets and mapped with Giraffe fast mode to reduce the computing cost.

\subsubsection{Pangenome genotyping workflow}

A genotyping pipeline was implemented in WDL and ran using the BioData Catalyst ecosystem\cite{bdc2020} providing access to the TOPMed and 1000 Genomes Project datasets.
The WDL pipeline was deposited on Dockstore\cite{vgsv_dockstore} and ran on Terra.
TOPMed data was accessed through Gen3.
The estimated cost per sample was estimated from Google Billing Reports.
Resources used for each sample or step in the workflow were extracted using \texttt{terra-utils} notebooks from the \href{https://biodatacatalyst.nhlbi.nih.gov/platforms/terra}{BioData Catalyst Powered by Terra}.
On average, genotyping a sample took 194.4 cpu-hours of compute and cost between \$1.11 and \$1.56 (Figure~\ref{fig:sv-wdl-graph}A, Tables~\ref{tab:svwdl-corehours} and \ref{tab:svwdl-task}).
Around 71\% of the time is spent mapping reads, 18\% genotyping the variants, and the remainder downloading and preparing the raw reads (Table~\ref{tab:svwdl-task}).


\subsubsection{Diverse sample selection from the MESA cohort}
\label{subsec:aim2:mesaselection}

The MESA cohort is a medical research study involving white, African American, Hispanic/Latino, and Chinese adults from 6 U.S. communities \cite{bild2002multi}.
We selected a subset of 2~thousand individuals in the MESA cohort from the TOPMed freeze 5b.
The individuals were selected to cover as uniformly as possible the space defined by the top 11 principal components provided by the TOPMed consortium.
These principal components (PCs) were derived from SNVs genotypes across the full TOPMed dataset.
Briefly, the selection process started with the two individuals that located the furthest from each other in the PC space.
New individuals were then selected, one by one, to maximize their distance to already selected individuals.


\subsubsection{Combining SV genotypes across samples}
\label{subsec:aim2:svcombining}

SVs were merged using bcftools version 1.9 \cite{li_samtools_2011}.
For each sample, we split multi-allelic variants, normalize them and sort the output VCF.
The output of \texttt{vg~call} is derived from paths in the graph (like haplotypes) that traverse the SV site.
For large SV sites, it means that one called variant may contain multiple smaller canonical SVs.
In addition, this path-based reporting of the variants can sometimes separate homozygous canonical variants into two heterozygous variants embedded within larger paths.
Hence, during normalization, we aligned the reference and alternate alleles in the VCF file to break down each variant into canonical SVs.
We also combined heterozygous variants that matched exactly into homozygous calls.
These SVs were then left-aligned and sorted using bcftools.
Finally, the VCF files were combined using \texttt{bcftools merge} using the \verb~-0 -m none~ parameters to avoid multi-allelic records.
The corresponding WDL workflow has been deposited on Dockstore\cite{svmerge_dockstore}.

\subsubsection{Clustering SV alleles into SV sites}
\label{subsec:aim2:svclustering}

Deletions were matched if their reciprocal overlap was at least 80\%.
Insertions were matched if located at less than 20 and their sizes were reciprocally similar at least 80\%.
Annotated simple repeats were also used to extend the range used to match SVs because similar variants might be placed in different position of an annotated VNTR.
We built a network using these matches to identify connected component representing SV sites where similar alleles cluster.
If the component formed a clique, i.e. all SVs matched all other SVs, the SV site contained alleles that differed by small variants (relative to the SV size).
If not, the SV site contained alleles with significant differences, usually due to important repeat expansion or contraction at a VNTR site.
For most analysis at the SV site level, we used the most frequent allele's information, such as boundaries or size.
The corresponding scripts are documented in the repository (see Section \ref{sec:aim2:code-data}).

\subsubsection{Allele frequency patterns across populations}
\label{subsec:aim2:sv-pop-freq}


We performed a principal component analysis of the individuals using the allele counts across all SV sites.
The allele counts represent the number of non-reference alleles called in each individual at each SV locus.

For the MESA cohort, we compared the principal components derived from the SV allele counts to the principal components produced by the TOPMed consortium using short variants.
Population information was not available for these individuals, so we used the top three principal components from our SV analysis to cluster them and explore population patterns further.
We used hierarchical clustering (\verb!ward.D! method in R's \verb!hclust! function) and cut the tree to obtain 6 clusters.

For the 1000 Genomes Project dataset, we used public information about the samples' super populations to color the PCA graphs and explore population patterns.

For each SV site, we compared the allele frequencies between the clusters/super populations.
To illustrate global population differences, we computed the range of allele frequencies across clusters/super populations.
This distribution was compared to an empirical null distribution produced by shuffling the population assignments.
As population-centric metric, we contrasted the allele frequency at each SV site in a super population versus the median allele frequency across all super populations.
Again, we used the null dataset to illustrate the enrichment in SVs whose frequency in the super population of interest is different from the global allele frequency.
We highlight SVs with a frequency differing by more than 10\% from the median frequency, a threshold at which only a few SVs are expected to show population patterns based on the permuted dataset.
The corresponding scripts are documented in the repository (see Section \ref{sec:aim2:code-data}).

\subsubsection{Comparison with existing large-scale SV catalogs}

We compared the variants genotyped in this study with three SV catalogs that screened large populations:

\begin{enumerate}
\item The 1000 Genomes Project phase 3\cite{1000gp_sv_2015} (2,504 individuals) downloaded from \url{http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/phase3/integrated_sv_map/supporting/GRCh38_positions/ALL.wgs.mergedSV.v8.20130502.svs.genotypes.GRCh38.vcf.gz}
\item gnomAD-SV\cite{gnomadsv_2020} v2 (more than 14~thousand individuals), lifted over to GRCh38
\item SVPOP\cite{audano_hgsvc} (440 individuals) downloaded from \url{http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/hgsv_sv_discovery/working/20181025_EEE_SV-Pop_1/VariantCalls_EEE_SV-Pop_1/EEE_SV-Pop_1.ALL.genotypes.20181204.vcf.gz}.
\end{enumerate}

These three public catalogs provide allele frequency estimate that we compared with the frequency of matched variants in our datasets.
Variants were matched with weaker matching criteria than before to avoid over-estimating the amount of novel variants.
We matched deletions with at least 30\% reciprocal overlap and insertions located at less than 200 bp from each other and at least 30\% reciprocally similar sizes.
Annotated simple repeats were also used to extend the range used to match SVs.
The corresponding scripts are documented in the repository (see Section \ref{sec:aim2:code-data}).

\subsubsection{Fine-tuning structural variants with frequencies}
\label{subsec:aim2:svfinetuning}

The frequency pattern across the different alleles at a SV site can help identify the discard alleles that contain errors.
We have found thousands of SV sites where one allele is much more frequent than the other.
Our most stringent definition selected 6,175 SV sites where the major allele is the only one with a frequencyhigher than 1\% while also being at least three times more frequent than any other alleles.

These alleles were indeed of better quality at the base level when we compared them to the GIAB catalog\cite{zook_robust_2020}, a SV catalog of unprecendented base quality.
Out of the 22 of those SV sites that were found in GIAB, 3 (13.6\%) matched exactly in terms of start/end position and size.
We show that it is significantly more than expected using permutation.
We permuted the frequency estimates 10,000 times and showed that, on average, only 2.9\% of SV sites would match GIAB exactly by chance (p-value $<$ 0.0001).

\subsubsection{Annotation of the SVs}

The RepeatMasker and SimpleRepeat annotation downloaded from the UCSC Genome Browser FTP server.
We considered a SV to overlap simple repeats if at least 50\% of its region overlapped with the SimpleRepeat track or repeats from the {\it Simple\_repeat} class in the RepeatMasker annotation.
Low-complexity regions were extracted from the RepeatMasker annotation.
The SVs were overlapped with gene annotation from Genecode v35.
Promoter regions were defined from 2~kbp up-stream to 200 bp downstream of the transcription start site.
We annotated SVs that overlapped coding regions, UTRs, promoters or introns of protein-coding genes, in this order.
This means that a SVs spanning a full gene is annotated as {\it coding}, or, for example, that a {\it promoter} SV overlapped neither coding nor untranslated regions.
Because the gene expression in the GEUVADIS is from lymphoblastoid cell lines, we used candidate regulatory regions for GM12878 from the ENCODE project\cite{encode1,encode2} (\href{https://www.encodeproject.org/files/ENCFF590IMH/}{ENCFF590IMH}) when annotating SV-eQTLs.
As before, a SV was preferentially annotated using the following order: coding, UTR, promoter, intron, regulatory region, intergenic region.


\subsubsection{Expression Quantitative Trait Locus discovery}
\label{subsec:aim2:eqtldiscovery}

We used gene expression provided by the GEUVADIS consortium\cite{geuvadis_2013}.
We tested for cis-eQTLs using a 1 Mbp range around the gene's transcription start site using Matrix eQTL\cite{matrix_eqtl_2012}.
First, all 445 samples with gene expression information were analyzed jointly.
Additionally, we also analyzed the CEU, FIN, GBR, and TSI samples together, and the YRI population separately.
In each analysis, we only tested SVs with a minor allele frequencies of at least 1\% and at least two samples with non-reference alleles.
The gene expression had been corrected for batch effects by the GEUVADIS consortium using PEER\cite{geuvadis_2013}.
To facilitate comparison of the predicted effect sizes, the gene expression distribution was centered and standardized before eQTL testing using the \verb!RowStandardizeCentered! function in Matrix eQTL.
Covariates of the model included sex and the top four principal components derived from the SV genotypes.
The p-values were corrected for multiple-testing using Benjamini-Hochberg correction.
We report eQTLs with an adjusted p-value (false discovery rate) of 1\%.
The p-value distributions and QQ plots were inspected for quality control.

We tested enrichment of SV-eQTLs in gene families extracted from the ``Families'' dataset of the HUGO Gene Nomenclature Committee (HGNC) BioMart server (downloaded March 15, 2021 from \url{https://biomart.genenames.org/}).
The 1,552 gene families were tested using a hypergenometric test comparing genes with eQTLs versus genes that were tested in the eQTL analysis.
The p-values were corrected for multiple testing using the Benjamini-Hochberg method.

We annotated each SV-eQTL using the gene annotation (see above).
SVs were split between SVs associated with increased or decreased gene expression.
As baseline for the functional overlaps, we selected genes with similar sizes as the genes involved in eQTLs.
We then selected all common SVs (allele frequency $\geq$ 1\%) and located at less than 1 Mbp of these genes.

Separate analysis of the four European-ancestry populations together, and the YRI population alone, identified respectively 44 and 139 SVs where an association with the expression of protein-coding genes was detected only in the smaller analysis.
Possible reasons for this include the 5\% frequency cutoff imposed on SV-eQTL candidates (which produced different sets of eligible variants in the different groups), the limited statistical power of the test (as the absence of a finding of an SV-eQTL is not the same as the finding of an absence of an SV-eQTL), and interactions between the candidate SV-eQTLs and the frequencies of other alleles or environmental factors which vary between the populations.
As expected, a number of these population-specific SV-eQTLs had shown strong inter-super-population frequency patterns (see Section \ref{subsec:aim2:inter-super-pop}):
19 out of the 44 CEU-FIN-GBR-TSI-specific SV-eQTLs and 10 out of the 139 YRI-specific SV-eQTLs showed such patterns.

We also performed a joint analysis that included the public SNV and indel calls generated at the New York Genome Center\cite{1000gp_nygc_2021}.
Phased SNVs and indels in the autosomes and with minor allele frequencies of at least 1\% were used for the eQTL analysis.
The same approach as described above was performed.
We defined the lead eQTL as the most significant association in a gene.

To evaluate the enrichment of SVs as lead eQTLs, we permuted the p-values within each gene 10,000 times to compute an empirical null distribution for the rate of lead SV-eQTL.
We also used permutation to test for an enrichment of SV-eQTLs or SNV/indel-eQTLs among highly expressed genes.
Genes were split in 20 expression classes based on their quantiles.
We then computed an empirical p-value for the proportion of eQTLs in each expression class using an empirical distribution derived from permuting the expression classes 10,000 times.
The p-values were corrected for multiple testing using the Benjamini-Hochberg method.

\section{Supplementary figures}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{HG002_v4.2.1_high_conf.35x_250bp.wgs.vcfevalroc.pdf}
    \caption[Genotyping evaluation for the Dragen genotyper with projected mappings from Giraffe and other mappers]{True positive and false positive genotypes made using the Dragen genotyper with projected mappings from Giraffe and other mappers, using 250bp paired-end reads from the HG002 GIAB sample and evaluated against the HG002 GIAB v4.2.1 truth variant call sets in high confidence regions. The ROC curve discrimination threshold is based on variant call quality.}
    \label{fig:250bp_genotyping}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{HG002_v4.2.1_high_conf.35x_150bp.wgs.vcfevalroc.1000GP_only.pdf}
    \caption[Genotyping evaluation for the Dragen genotyper with projected mappings from Giraffe and other mappers in 1000GP regions only]{True positive and false positive genotypes made using the Dragen genotyper with projected mappings from Giraffe and other mappers, using 150bp paired-end reads from the HG002 GIAB sample and evaluated against the HG002 GIAB v4.2.1 truth variant call sets in high confidence regions only within 1000GP variant regions. The ROC curve discrimination threshold is based on variant call quality.}
    \label{fig:150bp_genotyping_1000GP_only}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{HG002_v4.2.1_high_conf.35x_150bp.wgs.vcfevalroc.1000GP_excluded.pdf}
    \caption[Genotyping evaluation for the Dragen genotyper with projected mappings from Giraffe and other mappers in 1000GP excluded regions]{True positive and false positive genotypes made using the Dragen genotyper with projected mappings from Giraffe and other mappers, using 150bp paired-end reads from the HG002 GIAB sample and evaluated against the HG002 GIAB v4.2.1 truth variant call sets in high confidence regions with 1000GP variant regions excluded. The ROC curve discrimination threshold is based on variant call quality.}
    \label{fig:150bp_genotyping_1000GP_excluded}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{HG003_trained_deepvariant_genotyping.pdf}
    \caption[Genotyping evaluation for the DeepVariant genotyper with projected mappings from Giraffe and other mappers]{True positive and false positive genotypes made using the DeepVariant genotyper trained on alignments of 150bp paired-end reads from HG002 and HG004 GIAB samples and tested on 150bp paired-end reads from the HG003 GIAB sample and evaluated against the HG003 GIAB v4.2.1 truth variant call sets in high confidence regions. Dragen genotyper results are included for performance comparison. The ROC curve discrimination threshold is based on variant call quality.}
    \label{fig:trained_deepvariant_genotyping}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.9\linewidth, page=2]{fig-sveval.pdf}
    \caption[SV evaluation of vg and GraphTyper on HGSVC and GIAB]{{\bf SV evaluation of vg and GraphTyper on HGSVC and GIAB.}
      SV were genotyped with vg and GraphTyper and compared to the truthset from HGSVC\cite{chaisson_sv_2019} and GIAB\cite{zook_robust_2020}.
      When genotyping the HGSVC catalog, we used short-reads from the three individuals and one set of simulated reads for one individual.
      When genotyping the GIAB catalog, we genotyped SV from short-read for HG002.
      The y-axis shows the F1 score when assessing the presence/absence of a SV (semi-transparent bars) or exact genotype (opaque bars), for vg (red) and GraphTyper (blue).
      GraphTyper outputs multiple entries for the same variant which decreases the genotyping accuracy when including all the variants (light blue).
      To improve the genotyping performance, we selected one prediction per variant for GraphTyper (darker blue).
      Finally, insertions and deletions were evaluated separately (top vs bottom) on the whole genome or high-confidence regions (x-axis).
      Panels A, B, and C show the F1 score, precision, and recall, respectively.
      }
    \label{fig:graphtyper_eval}
\end{figure}

\begin{figure}[htp]
    \centering
    \includegraphics[width=.9\linewidth]{aim2_supplement_wdl-sveval.pdf}
    \caption[Structural variant genotyping workflow]{\textbf{Structural variant genotyping workflow.}
      (A, B, C) SV genotyping F1, precision, and recall (respectively) for the SV graph combining HGSVC \cite{chaisson_sv_2019}, SVPOP \cite{audano_hgsvc} and GIAB \cite{zook_robust_2020}, and for individual SV graphs containing only HGSVC or GIAB as used in Hickey et al.\cite{hickey_vgsv_2020}.
      The genotypes predicted from the long-read sequencing data in the original studies are used as truthset.
      (D) Workflow overview with average resources used for each task for a typical sample (Table \ref{tab:svwdl-task}). Note: the core hours estimates include the time spent copying files between computing instances.
    }
    \label{fig:sv-wdl-graph}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=.9\linewidth, page=1]{fig-sveval.pdf}
    \caption[Minimal effect of down-sampling reads to 20x depth on the SV genotyping performance]{{\bf Minimal effect of down-sampling reads to 20x depth on the SV genotyping performance.}
      HG00514 was genotyped using the SV graph combining HGSVC, SVPOP and GIAB.
      Panels A, B, and C show the F1 score, precision, and recall, respectively.
    }
    \label{fig:sveval-depth}
\end{figure}



\begin{figure}[H]
    \centering
    \includegraphics[width=.9\linewidth]{fig-sv-mesa-stats-2.pdf}
    \caption[SV alleles and SV sites in the MESA cohort]{{\bf SV alleles and SV sites in the MESA cohort.}
      (A) Proportion of SV loci in clique formation, i.e. with alleles different by only small variants (SNVs, indels) as opposed to large allelic variation such as VNTRs.
      The more alleles in a SV site the more likely it is to show VNTR-like allelic patterns.
      (B) Fold-change between the major allele and the second most frequent allele in a SV loci (y-axis), grouped by the number of alleles in the locus (x-axis).
      The number of loci with a fold-change higher than 3 (dotted line) are labeled.
    }
    \label{fig:svsites_mesa}
\end{figure}

\begin{figure}[H]
  \centering
  %~~~(A)\hfill{(B)~~~}

  %\includegraphics[width=.49\linewidth, page=1]{examples-svsites-mesa.pdf}
  %\includegraphics[width=.49\linewidth, page=2]{examples-svsites-mesa.pdf}

  %~~~(C)\hfill{(D)~~~}

  %\includegraphics[width=.49\linewidth, page=3]{examples-svsites-mesa.pdf}
  %\includegraphics[width=.49\linewidth, page=4]{examples-svsites-mesa.pdf}
  \includegraphics[width=\linewidth]{examples-svsites-mesa-all.pdf}
  \caption[Four examples of SV sites in the MESA cohort]{{\bf Four examples of SV sites in the MESA cohort.}
    For each site, the top left panel shows a representation of their configuration in the genomic region, the top right panel shows the distribution of allele frequencies across the 2000 MESA samples, and the bottom panel shows the result of a multiple-sequence alignment of the inserted/deleted sequences.
    In (A) and (B), the insertions' alleles are only different due to small variants while (C) and (D) shows an insertion and deletion site with significant size variation between the alleles.
    In (A), there is one major allele while multiple alleles of (B) are frequent in the population. }
  \label{fig:mesa-svsite-examples}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{fig-sv-1kgp-stats.pdf}
    \caption[Structural variants in 2,504 unrelated individuals from the 1000 Genomes Project]{\textbf{Structural variants in 2,504 unrelated individuals from the 1000 Genomes Project.}
      (A) Allele frequency distribution of the major allele for each SV loci.
      (B) Size distribution of the major allele for each SV loci.
      (C) Cumulative proportion of SV loci depending on the maximum number of alleles (x-axis) in the locus.
      (D) Proportion of SV loci in clique formation, i.e. with alleles different by only small variants (SNVs, indels) as opposed to large allelic variation such as VNTRs.
      The more alleles in a SV site the more likely it is to show VNTR-like allelic patterns.
      (E) Fold-change between the major allele and the second most frequent allele in a SV loci (y-axis), grouped by the number of alleles in the locus (x-axis).
      The number of loci with a fold-change higher than 3 (dotted line) are labeled.
    }
    \label{fig:sv-1kgp-stats}
\end{figure}



\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-sv-trio-eval.pdf}
  \caption[SV evaluation using 602 trios from the 1000 Genomes Project]{{\bf SV evaluation using 602 trios from the 1000 Genomes Project}
    (A) Mendelian error (y-axis) for different minimum genotype quality thresholds (x-axis), i.e. considering all variants where the minimum genotype quality in the trio is X or higher.
    (B) Proportion of transmitted allele from an heterozygous parent (y-axis) for the same minimum genotype quality thresholds (x-axis).
    In (A) and (B), the vertical lines represent the full error range across all trios while the point represents the median error.
    (C) Proportion of variants (y-axis) passing each minimum genotype quality threshold (x-axis).
  }
  \label{fig:sv-trio-eval}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-sv-freq-comp.pdf}
  \caption[Allele frequency of SVs in this study and public studies]{{\bf Allele frequency of SVs in this study and public studies.}
    (A) Allele frequency distribution of common variants (frequency >1\%) in each dataset.
    (B-D) show the difference in frequency between our results in the MESA cohort and each of the three public catalogs (1000 Genome Project phase 3, gnomAD-SV, SVPOP).
    (E-F) show the difference in frequency between SVPOP and the two other public catalogs.}
  \label{fig:sv-freq-comp}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth, page=3]{fig-sv-mesa-pcs.pdf}
  \caption[Principal component analysis using the SV genotypes or SNVs in the MESA dataset]{{\bf Principal component analysis using the SV genotypes (y-axis) in the MESA dataset compared to the principal components derived from TOPMed-wide SNVs (x-axis).}
    (A), (B), (C) compare the first, second and third components.}
  \label{fig:mesa-topmed-pcs}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-pops-freq-mesa.pdf}
  \caption[SV sites with population specific frequency patterns in the MESA cohort]{{\bf SV sites with population specific frequency patterns in the MESA cohort.}
    The two thousand MESA samples were clustered in 6 clusters based on the top 3 principal components (A-B).
    (C) The range of frequency, i.e. the difference between the maximum and minimum frequencies, across the sample clusters was larger than expected (permutation) for thousands of SV sites.
    (D) Two clusters (x-axis) show high number of population-specific SV sites (y-axis), defined as deviating from the median allele frequency by at least 10\%, 25\%, or 50\% (panels).}
  \label{fig:mesa-pop-freq}
\end{figure}


\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-sv-1kgp-pcs.pdf}
  \caption[PCA of SV genotypes in the 1000 Genomes Project]{{\bf Principal component analysis from structural variant genotypes across the 2,504 unrelated individuals in the 1000 Genomes Project dataset. }
    Principal component analysis was performed on the SV genotypes predicted by vg across the 166,199 SV loci.
    Individuals are colored according to their assigned ``super population'' in the 1000 Genomes Project.
    (A) shows the first and second principal components, (B) shows the third and fourth components.
  }
  \label{fig:1kgp-sv-pcs}
\end{figure}
\newpage

\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-pops-freq-kgp.pdf}
  \caption[SV sites with population specific frequency patterns in the 2,504 individuals from the 1000 Genomes Project]{{\bf SV sites with population specific frequency patterns in the 2,504 individuals from the 1000 Genomes Project. }
    (A) The range of frequency, i.e. the difference between the maximum and minimum frequencies, across the super-population was larger than expected (permutation) for thousands of SV sites.
    (B) Super-populations (x-axis) show high number of population-specific SV sites (y-axis), defined as deviating from the median allele frequency by at least 10\%, 25\%, or 50\% (panels).}
  \label{fig:1kgp-pop-freq}
\end{figure}


\begin{figure}[H]
  \includegraphics[width=\linewidth]{fig-sv-eqtl.pdf}
  \caption[P-value distribution of the SV vs gene expression tests in the GEUVADIS dataset]{{\bf P-value distribution of the SV vs gene expression tests in the GEUVADIS dataset.}
    Three analysis were performed: joint European and Yoruba populations (A-B), European populations only (C-D), and the Yoruba population (YRI) only (E-F).
    (A,C,E) show the p-value distribution, uniform except for the peak of low p-values.
    (B,D,F) show the QQ plots for the three analysis.
  }
  \label{fig:eqtl_qc}
  \end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth, page=2]{fig-sv-functional-summary.pdf}
  \caption[Location of the SV-eQTLs around the associated gene]{{\bf Location of the SV-eQTLs around the associated gene}
    The x-axis reports the proportion of SV-eQTLs overlapping each annotation group (panels).
    A SV-eQTL is either positively (red) or negatively (blue) associated with gene expression, i.e. each additional SV allele correlates with increased or decreased gene expression respectively.
    The control bar (green) represents the expected distribution of common SVs around control genes.
    Control genes were chosen to match the size distribution of genes involved in eQTLs.
    {\it UTR: untranslated region.}
  }
  \label{fig:eqtl_enr}
\end{figure}

\begin{figure}[H]
  \includegraphics[width=\linewidth, page=1]{fig-sv-snv-indel-eqtl.pdf}
  \caption[Enrichment of SV-eQTLs in highly expressed genes]{{\bf Enrichment of SV-eQTLs in highly expressed genes}
    Genes were split in 20 expression groups of equal size (quantiles).
    The graph shows the proportion of eQTLs (y-axis) in each expression quantile (x-axis).
    We see a strong enrichment for SV-eQTLs (blue) in the last quantile representing the mist expressed genes.
    The enrichment is also significant (point size) if only weaker for SNV/indel eQTLs.
    The horizontal dotted line represents the expected value, i.e. 1/20 of the eQTLs in each quantile group.
  }
  \label{fig:eqtl_enr_ge}
\end{figure}


\begin{figure}[H]
  \textsf{(A)} \hspace{15em} \textsf{(B)}

  \includegraphics[trim={0 0em 0 20em}, clip, width=\linewidth, page=2]{fig-sv-snv-indel-eqtl.pdf}
  \caption[Example of a SV lead-eQTL]{{\bf Example of SV lead-eQTL}
    Association between an intronic 5,405 bp deletion and the gene expression of the {\it SLC44A5} gene.
    (A) Each additional allele is associated with a decrease in gene expression.
    (B) shows the position of significant eQTLs (SNV/indels in green, deletion in red, insertion in blue).
    The y-axis represents the significance of the association, with the top eQTL being the highest point.
    The deletion is the most significant eQTLs and the significance decreases the farther the variant is from it.
  }
  \label{fig:eqtl_ex}
\end{figure}




\section{Supplementary tables}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|l|l|l|}
     \hline
    Pipeline                    & TP                 & FP              & FN              & Precision       & Sensitivity     & F-measure       \\
     \hline
    BWA-MEM                     & 3,866,030          & 22,519          & 24,392          & 0.9942          & 0.9937          & 0.9940          \\
    DRAGEN                      & 3,867,353          & \textbf{17,369} & 23,071          & \textbf{0.9955} & 0.9941          & 0.9948
         \\
    VG-MAP                      & 3,868,494          & 20,393          & 21,929          & 0.9948          & 0.9944          & 0.9946          \\
    Giraffe primary             & 3,869,525          & 18,308          & 20,909          & 0.9953          & 0.9946          & 0.9950          \\
    Giraffe                     & \textbf{3,871,501} & 17,787          & \textbf{18,917} & 0.9954          & \textbf{0.9951} & \textbf{0.9953} \\
    fast Giraffe                & 3,870,737          & 18,964          & 19,681          & 0.9951          & 0.9949          & 0.9950          \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with VCFeval in HG002 using 150bp paired-end reads against the grch38-based graph reference]{VCFeval performance of linear and graph-based pipelines against grch38-based references using 150bp paired-end reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:vcfeval_high_conf_2x150_hg002_grch38}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|r|r|r|l|l|l|}
     \hline
    Pipeline                                     & Var Type & TP                 & FN              & FP             & Recall            & Precision         & F1                \\
     \hline
     \multirow{2}{*}{BWA-MEM}                    & INDELS   & 522,406            & 3,063           & 2,723          & 0.994171          & 0.995028          & 0.994599          \\
                                                 & SNPS     & 3,343,857          & 21,270          & 19,780         & 0.993679          & 0.994121          & 0.993900          \\
    \hline
    \multirow{2}{*}{DRAGEN}                      & INDELS   & 522,618            & 2,851           & \textbf{2,478} & 0.994574          & \textbf{0.995475} & 0.995025 \\
                                                 & SNPS     & 3,344,971          & 20,156          & \textbf{14,868}& 0.994010          & \textbf{0.995576} & 0.994793          \\
    \hline
    \multirow{2}{*}{VG-MAP}                      & INDELS   & 522,643            & 2,826           & 2,689          & 0.994622          & 0.995092          & 0.994857          \\
                                                 & SNPS     & 3,346,085          & 19,042          & 17,677         & 0.994341          & 0.994746          & 0.994544          \\
    \hline
    \multirow{2}{*}{Giraffe primary}             & INDELS   & 522,657            & 2,812           & 2,608          & 0.994649          & 0.995239          & 0.994944          \\
                                                 & SNPS     & 3,347,097          & 18,030          & 15,672         & 0.994642          & 0.995341          & 0.994991          \\
    \hline
    \multirow{2}{*}{Giraffe}                     & INDELS   & \textbf{522,864}   & \textbf{2,605}  & 2,550          & \textbf{0.995043} & 0.995346          & \textbf{0.995194}          \\
                                                 & SNPS     & \textbf{3,348,882} & \textbf{16,245} & 15,213         & \textbf{0.995173} & 0.995479          & \textbf{0.995326} \\
    \hline
    \multirow{2}{*}{fast Giraffe}                & INDELS   & 522,825            & 2,644           & 2,583          & 0.994968          & 0.995286          & 0.995127          \\
                                                 & SNPS     & 3,348,156          & 16,971          & 16,358         & 0.994957          & 0.995139          & 0.995048          \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with Hap.py in HG002 using 150bp paired-end reads against the grch38-based graph reference]{Hap.py performance of linear and graph-based pipelines against grch38-based references using 150bp paired-end reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:happy_high_conf_2x150_hg002_grch38}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|l|l|l|}
     \hline
    Pipeline               & TP                 & FP              & FN              & Precision       & Sensitivity     & F-measure       \\
     \hline
    BWA-MEM                & 3,869,299          & 16,380          & 21,134          & 0.9958          & 0.9946          & 0.9952          \\
    DRAGEN                 & 3,870,566          & \textbf{12,863} & 19,864          & \textbf{0.9967} & 0.9949          & 0.9958          \\
    VG-MAP                 & 3,871,583          & 14,332          & 18,859          & 0.9963          & 0.9952          & 0.9957          \\
    Giraffe primary        & 3,873,118          & 13,640          & 17,331          & 0.9965          & 0.9955          & 0.9960          \\
    Giraffe                & \textbf{3,874,597} & 13,359          & \textbf{15,840} & 0.9966          & \textbf{0.9959} & \textbf{0.9962} \\
    fast Giraffe           & 3,874,104          & 13,695          & 16,334          & 0.9965          & 0.9958          & 0.9961          \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with VCFeval in HG002-exclusive variants using 250bp paired reads against the grch38-based graph reference]{VCFeval performance of linear and graph-based pipelines against grch38-based references using 250bp paired reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:vcfeval_high_conf_2x250_hg002_grch38}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|r|r|r|l|l|l|}
     \hline
    Pipeline                                     & Var Type & TP                 & FN              & FP             & Recall            & Precision         & F1                \\
     \hline
     \multirow{2}{*}{BWA-MEM}                    & INDELS   & 522,705            & 2,764           & 2,214          & 0.994740          & 0.995955          & 0.995347          \\
                                                 & SNPS     & 3,346,810          & 18,317          & 14,146         & 0.994557          & 0.995792          & 0.995174          \\
    \hline
    \multirow{2}{*}{DRAGEN}                      & INDELS   & 522,672            & 2,797           & \textbf{2,043} & 0.994677          & \textbf{0.996265} & 0.995471 \\
                                                 & SNPS     & 3,348,116          & 17,011          & \textbf{10,799}& 0.994945          & \textbf{0.996786} & 0.995865          \\
    \hline
    \multirow{2}{*}{VG-MAP}                      & INDELS   & 522,905            & 2,564           & 2,260          & 0.995121          & 0.995873          & 0.995497          \\
                                                 & SNPS     & 3,348,892          & 16,235          & 12,052         & 0.995176          & 0.996415          & 0.995795          \\
    \hline
    \multirow{2}{*}{Giraffe primary}             & INDELS   & 522,834            & 2,635           & 2,316          & 0.994985          & 0.995771          & 0.995378          \\
                                                 & SNPS     & 3,350,496          & 14,631          & 11,308         & 0.995652          & 0.996637          & 0.996144          \\
    \hline
    \multirow{2}{*}{Giraffe}                     & INDELS   & \textbf{523,148}   & \textbf{2,321}  & 2,177          & \textbf{0.995583} & 0.996026          & \textbf{0.995804}          \\
                                                 & SNPS     & \textbf{3,351,672} & \textbf{13,455} & 11,167         & \textbf{0.996002} & 0.996680          & \textbf{0.996341} \\
    \hline
    \multirow{2}{*}{fast Giraffe}                & INDELS   & 523,119            & 2,350           & 2,178          & 0.995528          & 0.996024          & 0.995776          \\
                                                 & SNPS     & 3,351,207          & 13,920          & 11,503         & 0.995863          & 0.996580          & 0.996222          \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with Hap.py in HG002 using 250bp paired reads against the grch38-based graph reference]{Hap.py performance of linear and graph-based pipelines against grch38-based references using 250bp paired reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:happy_high_conf_2x250_hg002_grch38}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|l|l|l|}
     \hline
    Pipeline                    & TP                 & FP              & FN              & Precision       & Sensitivity     & F-measure       \\
     \hline
    BWA-MEM                     & 3,370,702          & 1,678           & 4,248           & 0.9995          & 0.9987          & 0.9991         \\
    DRAGEN                      & 3,371,710          & \textbf{1,462}  & 3,296           & \textbf{0.9996} & 0.9990          & 0.9993         \\
    VG-MAP                      & 3,372,845          & 3,121           & 2,141           & 0.9991          & \textbf{0.9994} & 0.9992         \\
    Giraffe primary             & 3,371,806          & 1,501           & 3,143           & \textbf{0.9996} & 0.9991          & 0.9993        \\
    Giraffe                     & \textbf{3,373,044} & 1,543           & \textbf{1,934}  & 0.9995          & \textbf{0.9994} & \textbf{0.9995}\\
    fast Giraffe                & 3,372,947          & 1,684           & 2,028           & 0.9995          & \textbf{0.9994} & 0.9994 \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with VCFeval in HG002 using 150bp paired-end reads against the grch38-based graph reference in 1000GP variant regions]{VCFeval performance of linear and graph-based pipelines against grch38-based references using 150bp paired-end reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions only found in the 1000GP variant set used in constructing the graph references used by VG-MAP and Giraffe. Best values in each column are highlighted in bold text.}
\label{tab:vcfeval_high_conf_1000GP_only_2x150_hg002_grch38}
\end{table}

\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|l|l|l|}
     \hline
    Pipeline                    & TP                 & FP              & FN              & Precision       & Sensitivity     & F-measure       \\
     \hline
    BWA-MEM                     & 331,019            & 20,738          & 19,972          & 0.9410          & 0.9429          & 0.9420         \\
    DRAGEN                      & 331,381            & \textbf{15,819} & 19,643          & \textbf{0.9544} & 0.9438          & 0.9491          \\
    VG-MAP                      & 331,322            & 17,144          & 19,694          & 0.9508          & 0.9437          & 0.9472          \\
    Giraffe primary             & 333,362            & 16,714          & 17,638          & 0.9523          & 0.9496          & 0.9509         \\
    Giraffe                     & \textbf{334,122}   & 16,144          & \textbf{16,901} & 0.9539          & \textbf{0.9517} & \textbf{0.9528}\\
    fast Giraffe                & 333,452            & 17,182          & 17,569          & 0.9510          & 0.9498          & 0.9504         \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation with VCFeval in HG002 using 150bp paired-end reads against the grch38-based graph reference in regions excluding the 1000GP variant set]{VCFeval performance of linear and graph-based pipelines against grch38-based references using 150bp paired-end reads with respect to HG002 GIAB v4.2.1 truth variant call sets in high confidence regions excluding the 1000GP variant set used in constructing the graph references used by VG-MAP and Giraffe. Best values in each column are highlighted in bold text.}
\label{tab:vcfeval_high_conf_1000GP_excluded_2x150_hg002_grch38}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|l|r|r|r|l|l|l|}
     \hline
    Pipeline                    & TP                 & FP             & FN              & Precision       & Sensitivity     & F-measure       \\
     \hline
    BWA-MEM + Dragen            & 3,807,536          & 23,443         & 24,345          & 0.9939          & 0.9936          & 0.9938          \\
    Giraffe + Dragen            & \textbf{3,812,963} & 18,143         & \textbf{18,922} & 0.9953          & \textbf{0.9951} & 0.9952          \\
    Dragen MAP + Dragen         & 3,808,794          & 18,738         & 23,081          & 0.9951          & 0.9940          & 0.9945          \\
    BWA-MEM + DeepVariant       & 3,808,209          & \textbf{6,680} & 24,173          & \textbf{0.9982} & 0.9937          & 0.9960          \\
    Giraffe + DeepVariant       & 3,812,716          & 6,889          & 19,898          & \textbf{0.9982} & 0.9948          & \textbf{0.9965} \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation between DeepVariant calls of bwamem and giraffe 1000GP alignments against grch38-based references with RTG VCFeval in HG003 using 35x 150bp paired-end reads]{RTG VCFeval performance between DeepVariant and Dragen variant callers on grch38-based linear and giraffe 1000GP mappers using 150bp paired-end reads with respect to HG003 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:deepvariant_vcfeval_high_conf_2x150_50x_hg003_grch38}
\end{table}


\begin{table}[H]
    \centering
    \begin{tabular}{|l|c|r|r|r|l|l|l|}
     \hline
    Pipeline                                     & Var Type & TP                & FN             & FP            & Recall            & Precision         & F1                \\
    \hline
    \multirow{2}{*}{BWA-MEM+Dragen}           & INDELS    & 501,574           & 2,927          & 2,789         & 0.994198          & 0.994696      & 0.994447 \\
                                                & SNPS      & 3,306,162         & 21,331         & 20,642        & 0.993589          & 0.993797      & 0.993693 \\
    \hline
    \multirow{2}{*}{Giraffe+Dragen}           & INDELS    & \textbf{501,993}  & \textbf{2,508} & 2,566         & \textbf{0.995029} & 0.995122      & 0.995075 \\
                                                & SNPS      & \textbf{3,311,179}& \textbf{16,317}& 15,563        & \textbf{0.995096} & 0.995323      & 0.995210 \\
    \hline
    \multirow{2}{*}{DragenMAP+Dragen}        & INDELS    & 501,770           & 2,731          & 2,644         & 0.994587          & 0.994972      & 0.994780 \\
                                                & SNPS      & 3,307,236         & 20,260         & 16,078        & 0.993911          & 0.995163      & 0.994537 \\
    \hline
    \multirow{2}{*}{BWA-MEM+DeepVariant}      & INDELS    & 501,433           & 3,068          & \textbf{1,393}& 0.993919          & \textbf{0.997342} & 0.995627 \\
                                                & SNPS      & 3,306,484         & 21,012         & 5,268         & 0.993685          & 0.998410          & 0.996042 \\
    \hline
    \multirow{2}{*}{Giraffe+DeepVariant}      & INDELS    & 501,919           & 2,582          & 1,851         & 0.994882          & 0.996476          & \textbf{0.995678} \\
                                                & SNPS      & 3,310,338         & 17,158         & \textbf{5,015}& 0.994844          & \textbf{0.998488} & \textbf{0.996662} \\
    \hline
    \end{tabular}
\caption[Genotyping evaluation between DeepVariant calls of bwamem and giraffe 1000GP alignments against grch38-based references with Hap.py in HG003 using 35x 150bp paired-end reads]{Hap.py performance between DeepVariant and Dragen variant callers on grch38-based linear and giraffe 1000GP mappers using 150bp paired-end reads with respect to HG003 GIAB v4.2.1 truth variant call sets in high confidence regions. Best values in each column are highlighted in bold text.}
\label{tab:deepvariant_happy_high_conf_2x150_50x_hg003_grch38}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}[t]{|r|l|r|r|}
    \hline
    Pre-empted jobs & Dataset & Workflows & Core.hour \\
    \hline
    0               & all     & 2910      & 194.388   \\
    0               & MESA    & 1221      & 197.981   \\
    0               & 1000GP  & 1689      & 191.791   \\
    \hline
    1               & all     & 1358      & 220.046   \\
    1               & MESA    & 517       & 222.205   \\
    1               & 1000GP  & 841       & 218.718   \\
    \hline
    2               & all     & 439       & 240.992   \\
    2               & MESA    & 172       & 248.246   \\
    2               & 1000GP  & 267       & 236.318   \\
    \hline
    3+              & all     & 209       & 270.351   \\
    3+              & MESA    & 88        & 282.007   \\
    3+              & 1000GP  & 121       & 261.874   \\
    \hline
  \end{tabular}
  \caption[Computing resources used when genotyping 2,000 samples from the MESA cohort and 3,202 samples from the 1000 Genomes Project dataset]{{\bf Computing resources used when genotyping 2,000 samples from the MESA cohort and 3,202 samples from the 1000 Genomes Project dataset.}
    Pre-emptible instances on Google Cloud were used for all jobs.
    As expected, the average resource required was higher for workflows where some jobs were pre-empted.
    Note: The sequencing reads were down-sampled to $\sim$20x coverage.}
  \label{tab:svwdl-corehours}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}[t]{|l|c|c|c|l|}
    \hline
    \multirow{2}{*}{SV type} & \multicolumn{3}{|l|}{Number of non-reference alleles} & \multirow{2}{*}{Proportion of variants} \\
                             & Offspring                                             & Mother & Father &                       \\
    \hline
    \multirow{5}{*}{Deletion}     & 1                                                     & 0      & 0      & 0.0255409             \\
                             & 0                                                     & 2      & 0      & 0.0052011             \\
                             & 0                                                     & 0      & 2      & 0.0049499             \\
                             & 2                                                     & 0      & 0      & 0.0042598             \\
                             & 1                                                     & 2      & 2      & 0.0021315             \\
    \hline
    \multirow{5}{*}{Insertion}     & 1                                                     & 0      & 0      & 0.0224647             \\
                             & 1                                                     & 2      & 2      & 0.0045391             \\
                             & 0                                                     & 2      & 0      & 0.0037815             \\
                             & 0                                                     & 0      & 2      & 0.0036952             \\
                             & 2                                                     & 0      & 0      & 0.0030867             \\
    \hline
  \end{tabular}
  \caption[Most frequent Mendelian errors for SVs in the 1000GP trios]{{\bf Most frequent Mendelian error for SVs in the 1000GP trios.}
    The table shows the 5 most frequent Mendelian error configurations for deletions and insertions.
    For both SV types, the most frequent error is a predicted heterozygous variant in the offspring while both parents are predicted homozygous for the reference allele.
    Here all variants were included, i.e. no filtering based on genotype qualities was applied.
  }
  \label{tab:sv-mend-error}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}[t]{|l|l|r|r|r|}
    \hline
    Public SV & Dataset & Novel & Prop. of SVs in        & Prop. of common SVs in \\
    catalog   &         &       & public catalog covered & public catalog covered \\
    \hline
     1000GP   & MESA    & 0.932 & 0.160                  & 0.844                  \\
              & 1000GP  & 0.932 & 0.160                  & 0.844                  \\
    \hline
    gnomAD-SV & MESA    & 0.673 & 0.088                  & 0.628                  \\
              & 1000GP  & 0.670 & 0.087                  & 0.627                  \\
    \hline
  \end{tabular}
  \caption[Comparing SVs genotyped in the two datasets with two public SV catalogs]{{\bf Comparing SVs genotyped in the two datasets (MESA: 2,000 samples; 1000GP: 2,504 samples) with two public SV catalogs.}
    The table shows the proportion of novel SVs (not present in the public SV catalogs), and the proportion of SVs in the public catalog that are present in our results, either consering all variants or common variants (frequency greater or equal to 5\%).
    Deletions were matched if their reciprocal overlap was at least 30\%, insertions if located at less than 200 bp from each other and their size at least 30\% similar.
    Annotated simple repeats were used to extend the matching.
  }
  \label{tab:novel-sv}
\end{table}

\begin{table}[H]
  {\href{https://www.science.org/doi/suppl/10.1126/science.abg8871/suppl_file/science.abg8871_table_s21.zip}{supptab-S18-sv-eqtl.xlsx}}
  \caption[Gene families enriched in SV-eQTLs and eGenes with only SV-eQTLs]{{\bf Gene families enriched in SV-eQTLs and eGenes with only SV-eQTLs.}
    Excel file containing two sheets.
    The first lists gene families enriched in SV-eQTLs.
    The gene families were defined using the HUGO Gene Nomenclature Committee (HGNC) resource.
    The second lists the SV-eQTLs in genes where there are only SV associations, i.e. no SNV/indel eQTLs.
  }
  \label{tab:file-sveqtl}
\end{table}

\begin{table}[H]
  \centering
  \begin{tabular}[t]{|l|r|r|l|l|}
    \hline
    Task            & CPU & Memory (Gb) & Dataset & Core.hour        \\
    \hline
    CRAM conversion & 8   & 50          & all     & 12.867 (7.6\%)   \\
    CRAM conversion & 8   & 50          & MESA    & 13.22 (7.6\%)    \\
    CRAM conversion & 8   & 50          & 1000GP  & 12.636 (7.6\%)   \\
    \hline
    mapping         & 32  & 100         & all     & 146.261 (75.2\%) \\
    mapping         & 32  & 100         & MESA    & 157.66 (77.1\%)  \\
    mapping         & 32  & 100         & 1000GP  & 138.782 (73.9\%) \\
    \hline
    genotyping      & 16  & 100         & all     & 24.891 (17.2\%)  \\
    genotyping      & 16  & 100         & MESA    & 27.112 (15.4\%)  \\
    genotyping      & 16  & 100         & 1000GP  & 23.433 (18.5\%)  \\
    \hline
  \end{tabular}
  \caption[Computing resources for each task in the WDL genotyping workflow]{{\bf Computing resources for each task in the WDL genotyping workflow.}
    The table shows numbers for the workflows where no jobs were pre-empted.}
  \label{tab:svwdl-task}
\end{table}




%\todo{Tables below are not cited in main text}
\begin{table}[htb]
  \centering
  \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c|c}
    Mapper & Reads & Graph & vg version & Docker & xg & gcsa & lcp & gbwt & min & gg & dist  \\
    \hline
    VG-MAP & 150~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \mapindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter} \\
    VG-MAP & 250~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \mapindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter} \\
    Giraffe & 150~bp & Primary & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/primary_reference/primaryhs38d1}\\
    Giraffe & 250~bp & Primary & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/primary_reference/primaryhs38d1}\\
    Giraffe & 150~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter}\\
    Giraffe & 250~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter}\\
    Fast Giraffe & 150~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter}\\
    Fast Giraffe & 250~bp & 1000GP & \vgcommit{08faee067037ece539a237a008bcdefc84b681b0}{v1.31.0} & \docker{quay.io/vgteam/vg:v1.31.0} & \giraffeindexes{https://storage.googleapis.com/cmarkell-vg-wdl-dev/giraffe_manuscript_data/genome_references/graph_references/1000GPlons_hs38d1_filter}\\
  \end{tabular}
  \caption{Table of parameters for GRCh38-based genotyping experiment vg runs}
  \label{tab:vgruns_grch38}
  \label{tab:last}
\end{table}




% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% bibliography

% 2010june01 sol katzman:
% if \nocite is specified, all entries in the bib file are included,
% probably not what you want, so comment out the \nocite and only get the cited references.
%\nocite{*}

% 2010june01 sol katzman:
% this makes the bibliography single spaced, with double spacing between entries
\def\baselinestretch{1.0}\large\normalsize

\bibliographystyle{plain}
\bibliography{xian_chang_thesis}

\end{document}
